{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3일차 실습하기.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yunhyeongil/pandas_base/blob/main/3%EC%9D%BC%EC%B0%A8_%EC%8B%A4%EC%8A%B5%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj8a_HNCmk8y"
      },
      "source": [
        "## Bag of words (BOW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFMHSuyZmznQ"
      },
      "source": [
        "1. 통계와 머신러닝을 활용한 방법\n",
        "2. 인공 신경망을 활용한 방법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ov15ZmAnU2Q"
      },
      "source": [
        "doc1 = 'John likes to watch movies. Mary likes movies too.'\n",
        "\n",
        "BoW1 = {\"John\":1, \"likes\":2, \"to\":1, \"watch\":1, \"movies\":2, \"Mary\":1, \"too\":1}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9o994Ftnlhw"
      },
      "source": [
        "doc2 = 'Mary also likes to watch football games.'  \n",
        "BoW2 = {\"Mary\":1, \"also\":1, \"likes\":1, \"to\":1, \"watch\":1, \"football\":1, \"games\":1}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWaX4ArNn-bp"
      },
      "source": [
        "doc3 = 'John likes to watch movies. Mary likes movies too. Mary also likes to watch football games.'  \n",
        "BoW3 = {\"John\":1, \"likes\":3, \"to\":2, \"watch\":2, \"movies\":2, \"Mary\":2, \"too\":1, \"also\":1, \"football\":1, \"games\":1};\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiXwrUqBoMCB"
      },
      "source": [
        "## keras Tokenizer를 활용한 BOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e3bu6YtmwP6"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "sentence = [\"John likes to watch movies. Mary likes movies too! Mary also likes to watch football games.\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9cyc3lWoU3S",
        "outputId": "bab2275e-c624-4ead-926b-42c2f06a07d5"
      },
      "source": [
        "def print_bow(sentence):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(sentence) # 단어장 생성\n",
        "  bow = dict(tokenizer.word_counts) # 각 단어와 각 단어의 빈도를 bow에 저장\n",
        "  print(\"Bag of words :\", bow) #bow출력\n",
        "  print('단어장(vocabulary)의 크기 :', len(tokenizer.word_counts)) # 중복을 제거한 단어들의 갯수\n",
        "\n",
        "print_bow(sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bag of words : {'john': 1, 'likes': 3, 'to': 2, 'watch': 2, 'movies': 2, 'mary': 2, 'too': 1, 'also': 1, 'football': 1, 'games': 1}\n",
            "단어장(vocabulary)의 크기 : 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuiCKRuupaO_"
      },
      "source": [
        "## scikit-learn CountVectorizer활용한 BOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDXSF8xYo8UY",
        "outputId": "4a366a1f-5e4f-4a4e-8bfb-166f0b2a10d6"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "sentence = [\"John likes to watch movies. Mary likes movies too! Mary also likes to watch football games.\"]\n",
        "\n",
        "vector = CountVectorizer()\n",
        "print('Bag of Words : ', vector.fit_transform(sentence).toarray()) # 코퍼스로부터 각 단어의 빈도수를 기록\n",
        "print('각 단어의 인덱스: ', vector.vocabulary_) # 각 단어의 인덱스가 어떻게 부여되는지를 보여줌.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bag of Words :  [[1 1 1 1 3 2 2 2 1 2]]\n",
            "각 단어의 인덱스:  {'john': 3, 'likes': 4, 'to': 7, 'watch': 9, 'movies': 6, 'mary': 5, 'too': 8, 'also': 0, 'football': 1, 'games': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c31BNRbp2pH",
        "outputId": "d9636a06-f30b-4209-8054-8b949f0899f8"
      },
      "source": [
        "print('단어장(vocabulary)의 크기 :', len(vector.vocabulary_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어장(vocabulary)의 크기 : 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2p5L8Yvqm0H"
      },
      "source": [
        "## DTM (Document-Term Matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNikoe27q1U_"
      },
      "source": [
        "문서 1 : I like dog  \n",
        "문서 2 : I like cat  \n",
        "문서 3 : I like cat I like cat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "cNf-o2XrvbA5",
        "outputId": "18e42681-fe0f-4283-94d4-221ac33135ac"
      },
      "source": [
        "import pandas as pd\n",
        "content = [[0,1,1,1],[1,0,1,1],[2,0,2,2,]]\n",
        "df = pd.DataFrame(content)\n",
        "df.index = ['문서1', '문서2', '문서3']\n",
        "df.columns = ['cat', 'dog', 'I', 'like']\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cat</th>\n",
              "      <th>dog</th>\n",
              "      <th>I</th>\n",
              "      <th>like</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>문서1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>문서2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>문서3</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     cat  dog  I  like\n",
              "문서1    0    1  1     1\n",
              "문서2    1    0  1     1\n",
              "문서3    2    0  2     2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgj8Q-NnqaSJ"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import dot \n",
        "from numpy.linalg import norm\n",
        "\n",
        "doc1 = np.array([0, 1, 1, 1])\n",
        "doc2 = np.array([1, 0, 1, 1])\n",
        "doc3 = np.array([2, 0, 2, 2])\n",
        "\n",
        "def cos_sim(A, B):\n",
        "  return dot(A, B)/(norm(A)*norm(B))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erP-u2-0rsri",
        "outputId": "d2e93388-37dc-485c-dbe2-df50e8c1a113"
      },
      "source": [
        "print(cos_sim(doc1, doc2)) \n",
        "print(cos_sim(doc1, doc3))\n",
        "print(cos_sim(doc2, doc3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6666666666666667\n",
            "0.6666666666666667\n",
            "1.0000000000000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbXdQldEsBB2"
      },
      "source": [
        "DTM에서는 코사인 유사도는 0이상 1이하의 값을 가지고, 값이 1에 가까울수록 유사도 높다 판단"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb_MboQqsI72"
      },
      "source": [
        "## scikit-learn CountVectorizer활용한 DTM구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrGF3uP8r4Kn",
        "outputId": "90af47a2-3f48-4c13-eb3d-226464d1702f"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = [\n",
        "          'John likes to watch movies',\n",
        "          'Mary likes movies too',\n",
        "          'Mary also likes to watch football games',\n",
        "]\n",
        "\n",
        "vector = CountVectorizer()\n",
        "print(vector.fit_transform(corpus).toarray()) # 코퍼스로부터 각 단어의 빈도수를 기록\n",
        "print(vector.vocabulary_) # 각 단어의 인덱스가 어떻게 부여되었는지 보여준다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 1 1 0 1 1 0 1]\n",
            " [0 0 0 0 1 1 1 0 1 0]\n",
            " [1 1 1 0 1 1 0 1 0 1]]\n",
            "{'john': 3, 'likes': 4, 'to': 7, 'watch': 9, 'movies': 6, 'mary': 5, 'too': 8, 'also': 0, 'football': 1, 'games': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at8HYVG0tGlY"
      },
      "source": [
        "## TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo1G0v9Ltl6I"
      },
      "source": [
        "모든 문서에서 자주 등장하는 단어는 중요도가 낮다고 판단하며, 특정 문서에서만 자주 등장하는 단어는 중요도가 높다고 판단하는 것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYIiY_w9tvsf"
      },
      "source": [
        "단어의 빈도  \n",
        "문서의 빈도의 역수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92xh8195soCQ"
      },
      "source": [
        "from math import log\n",
        "import pandas as pd\n",
        "\n",
        "docs = [\n",
        "        'John likes to watch movies and Mary likes movies too',\n",
        "        'James likes to watch TV',\n",
        "        'Mary also likes to watch football games',\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GISuyN_uS_I",
        "outputId": "369d7701-88c4-4175-e135-eca2abf47ae8"
      },
      "source": [
        "vocab = list(set(w for doc in docs for w in doc.split()))\n",
        "vocab.sort()\n",
        "print('단어장의 크기 :', len(vocab))\n",
        "print(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어장의 크기 : 13\n",
            "['James', 'John', 'Mary', 'TV', 'also', 'and', 'football', 'games', 'likes', 'movies', 'to', 'too', 'watch']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxGiUHv6uiwG",
        "outputId": "a2cf0b22-af46-4fbf-fdf2-80179b662682"
      },
      "source": [
        "N = len(docs)\n",
        "N"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_iQ88yiun0W"
      },
      "source": [
        "def tf(t,d):\n",
        "  return d.count(t)\n",
        "\n",
        "def idf(t):\n",
        "  df = 0\n",
        "  for doc in docs:\n",
        "    df += t in doc\n",
        "  return log(N/(df + 1))+1\n",
        "\n",
        "def tfidf(t, d):\n",
        "  return tf(t,d)* idf(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qbE4lTTu-q2"
      },
      "source": [
        "TF함수를 사용하여 DTM을 만들어보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "MKSvKBtiu8ZW",
        "outputId": "5b4680db-7d63-4d8e-ba1e-537e1ef5cb90"
      },
      "source": [
        "result = []\n",
        "for i in range(N): # 각 문서에 대해서 아래 명령을 수행\n",
        "  result.append([])\n",
        "  d = docs[i]\n",
        "  for j in range(len(vocab)):\n",
        "    t = vocab[j]\n",
        "\n",
        "    result[-1].append(tf(t,d))\n",
        "\n",
        "tf_ = pd.DataFrame(result, columns=vocab)\n",
        "tf_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>James</th>\n",
              "      <th>John</th>\n",
              "      <th>Mary</th>\n",
              "      <th>TV</th>\n",
              "      <th>also</th>\n",
              "      <th>and</th>\n",
              "      <th>football</th>\n",
              "      <th>games</th>\n",
              "      <th>likes</th>\n",
              "      <th>movies</th>\n",
              "      <th>to</th>\n",
              "      <th>too</th>\n",
              "      <th>watch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   James  John  Mary  TV  also  and  ...  games  likes  movies  to  too  watch\n",
              "0      0     1     1   0     0    1  ...      0      2       2   2    1      1\n",
              "1      1     0     0   1     0    0  ...      0      1       0   1    0      1\n",
              "2      0     0     1   0     1    0  ...      1      1       0   1    0      1\n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "-GeLPG2NvUz-",
        "outputId": "1b1335f6-5cdf-412e-e92b-2c1f744db32c"
      },
      "source": [
        "result = []\n",
        "for j in range(len(vocab)):\n",
        "  t = vocab[j]\n",
        "  result.append(idf(t))\n",
        "\n",
        "idf_ = pd.DataFrame(result, index = vocab, columns = [\"IDF\"])\n",
        "idf_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IDF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>James</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>John</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mary</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TV</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>also</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>and</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>football</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>games</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>likes</th>\n",
              "      <td>0.712318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>movies</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>0.712318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>too</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>watch</th>\n",
              "      <td>0.712318</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               IDF\n",
              "James     1.405465\n",
              "John      1.405465\n",
              "Mary      1.000000\n",
              "TV        1.405465\n",
              "also      1.405465\n",
              "and       1.405465\n",
              "football  1.405465\n",
              "games     1.405465\n",
              "likes     0.712318\n",
              "movies    1.405465\n",
              "to        0.712318\n",
              "too       1.405465\n",
              "watch     0.712318"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLMnmjtwAHG"
      },
      "source": [
        "TF-IDF행렬을 출력 DTM에 있는 각 단어의 TF에 각 단어의 iDF를 곱해준 값"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "3s-EB16XvsvI",
        "outputId": "f9cbac89-0073-4134-818a-55204326b381"
      },
      "source": [
        "result = []\n",
        "for i in range(N):\n",
        "  result.append([])\n",
        "  d = docs[i]\n",
        "  for j in range(len(vocab)):\n",
        "    t = vocab[j]\n",
        "\n",
        "    result[-1].append(tfidf(t,d))\n",
        "\n",
        "tfidf_ = pd.DataFrame(result, columns= vocab)\n",
        "tfidf_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>James</th>\n",
              "      <th>John</th>\n",
              "      <th>Mary</th>\n",
              "      <th>TV</th>\n",
              "      <th>also</th>\n",
              "      <th>and</th>\n",
              "      <th>football</th>\n",
              "      <th>games</th>\n",
              "      <th>likes</th>\n",
              "      <th>movies</th>\n",
              "      <th>to</th>\n",
              "      <th>too</th>\n",
              "      <th>watch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.424636</td>\n",
              "      <td>2.81093</td>\n",
              "      <td>1.424636</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>0.712318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.405465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.712318</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.712318</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.712318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>0.712318</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.712318</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.712318</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      James      John  Mary        TV  ...   movies        to       too     watch\n",
              "0  0.000000  1.405465   1.0  0.000000  ...  2.81093  1.424636  1.405465  0.712318\n",
              "1  1.405465  0.000000   0.0  1.405465  ...  0.00000  0.712318  0.000000  0.712318\n",
              "2  0.000000  0.000000   1.0  0.000000  ...  0.00000  0.712318  0.000000  0.712318\n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lciuP0bJwU1I"
      },
      "source": [
        "'John likes to watch movies and Mary likes movies too',\n",
        "'James likes to watch TV',\n",
        "'Mary also likes to watch football games',\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycggqoZkwuLV"
      },
      "source": [
        "## scikit-learn TFidVectorizer활용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "THBkzW4iwrln",
        "outputId": "f3f7cc70-432d-4b26-e551-04e204e07a2a"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "corpus = [\n",
        "          'John likes to watch movies and Mary likes movies too',\n",
        "          'James likes to watch TV',\n",
        "          'Mary also likes to watch football games',\n",
        "]\n",
        "\n",
        "tfidfv = TfidfVectorizer().fit(corpus)\n",
        "vocab = list(set(tfidfv.vocabulary_.keys()))\n",
        "vocab.sort()\n",
        "\n",
        "tfidf_ = pd.DataFrame(tfidfv.transform(corpus).toarray(), columns=vocab)\n",
        "tfidf_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>also</th>\n",
              "      <th>and</th>\n",
              "      <th>football</th>\n",
              "      <th>games</th>\n",
              "      <th>james</th>\n",
              "      <th>john</th>\n",
              "      <th>likes</th>\n",
              "      <th>mary</th>\n",
              "      <th>movies</th>\n",
              "      <th>to</th>\n",
              "      <th>too</th>\n",
              "      <th>tv</th>\n",
              "      <th>watch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.321556</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.321556</td>\n",
              "      <td>0.379832</td>\n",
              "      <td>0.244551</td>\n",
              "      <td>0.643111</td>\n",
              "      <td>0.189916</td>\n",
              "      <td>0.321556</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.189916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.572929</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.338381</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.338381</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.572929</td>\n",
              "      <td>0.338381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.464997</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.464997</td>\n",
              "      <td>0.464997</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.274634</td>\n",
              "      <td>0.353642</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.274634</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.274634</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       also       and  football  ...       too        tv     watch\n",
              "0  0.000000  0.321556  0.000000  ...  0.321556  0.000000  0.189916\n",
              "1  0.000000  0.000000  0.000000  ...  0.000000  0.572929  0.338381\n",
              "2  0.464997  0.000000  0.464997  ...  0.000000  0.000000  0.274634\n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54DkcOY0xUuZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3gXKYZ61yRO"
      },
      "source": [
        "LSA  (잠재의미분석)  \n",
        "전체 코퍼스에서 문자 속 단어들 상의 관계를 찾아내는 자연어 처리 정보검색 기술\n",
        "단어와 단어사이, 문서와 문서사이, 단어와 문서사이의 의미적 유사성 점수를 찾아낸다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLIkDVy610eG"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Gkhe1ov3GUN"
      },
      "source": [
        "!pip install nltk # nltk 설치"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Leq6Af2z3KWR",
        "outputId": "c5dfc7c4-9abd-4855-c558-a8b96461de00"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKRmkW5-3b2d",
        "outputId": "abb3378f-c7f2-4b7e-a1ad-5b33aa9611a7"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBJmrRTV3mXl",
        "outputId": "264629dc-5bc6-42e4-81cc-3792b0e55ae8"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/franciscadias/data/master/abcnews-date-text.csv\",\n",
        "                           filename=\"/content/abcnews-data-text.csv\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/abcnews-data-text.csv', <http.client.HTTPMessage at 0x7fb92a09c950>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "H8kGLa_w4pWd",
        "outputId": "872af487-1292-484c-fa4e-ee2a02ad64f2"
      },
      "source": [
        "data = pd.read_csv('/content/abcnews-data-text.csv', error_bad_lines=False)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>publish_date</th>\n",
              "      <th>headline_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20030219</td>\n",
              "      <td>aba decides against community broadcasting lic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20030219</td>\n",
              "      <td>act fire witnesses must be aware of defamation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20030219</td>\n",
              "      <td>a g calls for infrastructure protection summit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20030219</td>\n",
              "      <td>air nz staff in aust strike for pay rise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20030219</td>\n",
              "      <td>air nz strike to affect australian travellers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1082163</th>\n",
              "      <td>20170630</td>\n",
              "      <td>when is it ok to compliment a womans smile a g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1082164</th>\n",
              "      <td>20170630</td>\n",
              "      <td>white house defends trumps tweet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1082165</th>\n",
              "      <td>20170630</td>\n",
              "      <td>winter closes in on tasmania as snow ice falls</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1082166</th>\n",
              "      <td>20170630</td>\n",
              "      <td>womens world cup australia wins despite atapat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1082167</th>\n",
              "      <td>20170630</td>\n",
              "      <td>youtube stunt death foreshadowed by tweet</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1082168 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         publish_date                                      headline_text\n",
              "0            20030219  aba decides against community broadcasting lic...\n",
              "1            20030219     act fire witnesses must be aware of defamation\n",
              "2            20030219     a g calls for infrastructure protection summit\n",
              "3            20030219           air nz staff in aust strike for pay rise\n",
              "4            20030219      air nz strike to affect australian travellers\n",
              "...               ...                                                ...\n",
              "1082163      20170630  when is it ok to compliment a womans smile a g...\n",
              "1082164      20170630                   white house defends trumps tweet\n",
              "1082165      20170630     winter closes in on tasmania as snow ice falls\n",
              "1082166      20170630  womens world cup australia wins despite atapat...\n",
              "1082167      20170630          youtube stunt death foreshadowed by tweet\n",
              "\n",
              "[1082168 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "7BMJn2Ib5TN7",
        "outputId": "995f7b26-c7ad-4293-d7f1-c4d77ddfc716"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>publish_date</th>\n",
              "      <th>headline_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20030219</td>\n",
              "      <td>aba decides against community broadcasting lic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20030219</td>\n",
              "      <td>act fire witnesses must be aware of defamation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20030219</td>\n",
              "      <td>a g calls for infrastructure protection summit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20030219</td>\n",
              "      <td>air nz staff in aust strike for pay rise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20030219</td>\n",
              "      <td>air nz strike to affect australian travellers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   publish_date                                      headline_text\n",
              "0      20030219  aba decides against community broadcasting lic...\n",
              "1      20030219     act fire witnesses must be aware of defamation\n",
              "2      20030219     a g calls for infrastructure protection summit\n",
              "3      20030219           air nz staff in aust strike for pay rise\n",
              "4      20030219      air nz strike to affect australian travellers"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "pr-74qsO55Zl",
        "outputId": "3b4219a6-99d6-46a9-b285-3997a43dc8d2"
      },
      "source": [
        "text = data[['headline_text']]\n",
        "text.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aba decides against community broadcasting lic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>act fire witnesses must be aware of defamation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a g calls for infrastructure protection summit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>air nz staff in aust strike for pay rise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>air nz strike to affect australian travellers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       headline_text\n",
              "0  aba decides against community broadcasting lic...\n",
              "1     act fire witnesses must be aware of defamation\n",
              "2     a g calls for infrastructure protection summit\n",
              "3           air nz staff in aust strike for pay rise\n",
              "4      air nz strike to affect australian travellers"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_4QsOmq6ElF",
        "outputId": "cafe34f1-2713-486f-ea21-696542ceeb96"
      },
      "source": [
        "text.nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "headline_text    1054983\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr1gDbBC6Ott",
        "outputId": "c100a58a-e842-4383-ffc9-9de9072a39d6"
      },
      "source": [
        "# 중복 제거\n",
        "text.drop_duplicates(inplace=True)\n",
        "text = text.reset_index(drop=True)\n",
        "print(len(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1054983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKvHVXY_6lKF"
      },
      "source": [
        "데이터 정제 및 정규화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAQiV-IG6iTP"
      },
      "source": [
        "text['headline_text'] = text.apply(lambda row:nltk.word_tokenize(row['headline_text']), axis=1)\n",
        "# NLTK 토크나이저를 이용해서 토큰화"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oooe0CKn61Pu"
      },
      "source": [
        "# 불용어 제거\n",
        "stop_words = stopwords.words('english')\n",
        "text['headline_text'] = text['headline_text'].apply(lambda x: [word for word in x if word not in (stop_words) ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "07obEyOe7lUE",
        "outputId": "a5cbc4a3-d508-4a75-9535-61423c3ca1bf"
      },
      "source": [
        "text.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[aba, decides, community, broadcasting, licence]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[act, fire, witnesses, must, aware, defamation]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[g, calls, infrastructure, protection, summit]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[air, nz, staff, aust, strike, pay, rise]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[air, nz, strike, affect, australian, travellers]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       headline_text\n",
              "0   [aba, decides, community, broadcasting, licence]\n",
              "1    [act, fire, witnesses, must, aware, defamation]\n",
              "2     [g, calls, infrastructure, protection, summit]\n",
              "3          [air, nz, staff, aust, strike, pay, rise]\n",
              "4  [air, nz, strike, affect, australian, travellers]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c2BcgfX7rZU"
      },
      "source": [
        "# 단어 정규화 과정 길이가 1~2인 단어는 제거하는 전처리\n",
        "# 단어 정규화 3인칭 단수 표현 -> 1인칭 변환, 과거형 동사 -> 현재형 동사등을 수행\n",
        "text['headline_text'] = text['headline_text'].apply(lambda x : [WordNetLemmatizer().lemmatize(word, pos='v') for word in x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fZwum0L8Dak",
        "outputId": "01a4129c-04ba-42d6-a4a3-63c91d99e868"
      },
      "source": [
        "# 길이가 1~2인 단어를 제거\n",
        "text = text['headline_text'].apply(lambda x : [word for word in x if len(word) > 2])\n",
        "print(text[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0     [aba, decide, community, broadcast, licence]\n",
            "1    [act, fire, witness, must, aware, defamation]\n",
            "2       [call, infrastructure, protection, summit]\n",
            "3            [air, staff, aust, strike, pay, rise]\n",
            "4    [air, strike, affect, australian, travellers]\n",
            "Name: headline_text, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cON9s0lj8jFU"
      },
      "source": [
        "# 역토큰화 (토큰화 작업을 역으로 수행)\n",
        "detokenized_doc=[]\n",
        "for i in range(len(text)):\n",
        "  t = ' '.join(text[i])\n",
        "  detokenized_doc.append(t)\n",
        "\n",
        "train_data = detokenized_doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecfVK1RH8-lW",
        "outputId": "b5549d53-18dc-477b-cc02-2b60fbcb0700"
      },
      "source": [
        "train_data[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aba decide community broadcast licence',\n",
              " 'act fire witness must aware defamation',\n",
              " 'call infrastructure protection summit',\n",
              " 'air staff aust strike pay rise',\n",
              " 'air strike affect australian travellers']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVWgjFK19D_N"
      },
      "source": [
        "# 상위 5000개의 단어만 사용\n",
        "c_vectorizer = CountVectorizer(stop_words='english', max_features= 5000)\n",
        "document_term_matrix = c_vectorizer.fit_transform(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSKybzkm9WsN",
        "outputId": "6c9bc59f-a8a7-4f6a-db4e-0a77ac08d6a0"
      },
      "source": [
        "# DTM의 크기\n",
        "print('행렬의 크기 : ', document_term_matrix.shape) # 문서의 수 X 단어 집합의 크기"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "행렬의 크기 :  (1054983, 5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBXA87Td9v0d"
      },
      "source": [
        "## scikit-learn Truncated SVD 활용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zTEBtCh9h00",
        "outputId": "d0618006-4c3d-4bfd-cc38-30a94e4b687f"
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "n_topics = 10\n",
        "lsa_model = TruncatedSVD(n_components = n_topics)\n",
        "lsa_model.fit_transform(document_term_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.20521326e-02, -3.48046348e-03,  1.82930127e-02, ...,\n",
              "         4.21162626e-03,  1.57086733e-03,  1.36404632e-02],\n",
              "       [ 2.90583638e-02, -1.06335385e-02,  1.83280393e-02, ...,\n",
              "        -2.16334430e-03,  1.48459022e-02,  2.33238570e-03],\n",
              "       [ 5.05690092e-03, -1.98543190e-03,  9.76135386e-03, ...,\n",
              "        -2.11086531e-03, -5.36211311e-04,  1.56445177e-03],\n",
              "       ...,\n",
              "       [ 2.95459352e-02,  4.74589139e-03,  2.52650803e-02, ...,\n",
              "         4.82012249e-02, -2.99384210e-04,  1.34999640e-02],\n",
              "       [ 6.27711471e-02, -3.16910012e-03,  1.35962749e-01, ...,\n",
              "         9.08226397e-01, -5.89549233e-01, -4.42823297e-01],\n",
              "       [ 7.08766649e-02,  2.87881634e-02,  2.94852249e-03, ...,\n",
              "         5.90338355e-02,  5.17380562e-02,  3.42562060e-02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKVezVsn-KM1",
        "outputId": "5e40c45d-51ba-4c80-8204-df9db65da91f"
      },
      "source": [
        "print(np.shape(lsa_model.components_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8O-74CC-RIM"
      },
      "source": [
        "terms = c_vectorizer.get_feature_names()\n",
        "\n",
        "def get_topics(components, feature_names, n=5):\n",
        "  for idx, topic in enumerate(components):\n",
        "    print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n - 1:-1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_IrYqKv-vMd",
        "outputId": "f742a28e-5f09-4266-9285-76701b268e52"
      },
      "source": [
        "get_topics(lsa_model.components_, terms)\n",
        "# LSA에 대한 결과물"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 1: [('police', 0.74635), ('man', 0.45356), ('charge', 0.21096), ('new', 0.14087), ('court', 0.11139)]\n",
            "Topic 2: [('man', 0.69418), ('charge', 0.30063), ('court', 0.16782), ('face', 0.11278), ('murder', 0.10703)]\n",
            "Topic 3: [('new', 0.83662), ('plan', 0.23634), ('say', 0.18261), ('govt', 0.1106), ('council', 0.11005)]\n",
            "Topic 4: [('say', 0.73912), ('plan', 0.3584), ('govt', 0.1669), ('council', 0.13221), ('fund', 0.07747)]\n",
            "Topic 5: [('plan', 0.73237), ('council', 0.17599), ('govt', 0.13929), ('urge', 0.08747), ('water', 0.06783)]\n",
            "Topic 6: [('govt', 0.53989), ('urge', 0.26525), ('court', 0.25895), ('fund', 0.19743), ('face', 0.16252)]\n",
            "Topic 7: [('charge', 0.52503), ('court', 0.44167), ('face', 0.34383), ('murder', 0.12519), ('plan', 0.11169)]\n",
            "Topic 8: [('win', 0.62011), ('court', 0.28674), ('kill', 0.19423), ('crash', 0.16968), ('australia', 0.09817)]\n",
            "Topic 9: [('court', 0.57781), ('accuse', 0.12162), ('face', 0.08706), ('tell', 0.08048), ('qld', 0.08005)]\n",
            "Topic 10: [('council', 0.64969), ('kill', 0.31499), ('crash', 0.19391), ('car', 0.09393), ('charge', 0.08827)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brtKELeiDMcM"
      },
      "source": [
        "TF-IDF 행렬 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ObPS8UD-zJ8",
        "outputId": "f829e36e-c017-4f6b-c951-a4af99e2ba6c"
      },
      "source": [
        "# 상위 5000개의 단어만 사용\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features = 5000)\n",
        "tf_idf_matrix = tfidf_vectorizer.fit_transform(train_data)\n",
        "\n",
        "# TF-IDF행렬의 크기를 확인\n",
        "print('행렬의 크기 : ', tf_idf_matrix.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "행렬의 크기 :  (1054983, 5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG_ml7QUDtkb"
      },
      "source": [
        "scikit-learn LDA model활용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybC6Z6WtDnKl",
        "outputId": "617a2bbd-f0d0-48a2-ca0c-229de657878a"
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "lda_model = LatentDirichletAllocation(n_components = 10, learning_method = 'online', random_state = 777, max_iter=1)\n",
        "lda_model.fit_transform(tf_idf_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0335099 , 0.0335099 , 0.0335099 , ..., 0.17024867, 0.0335099 ,\n",
              "        0.0335099 ],\n",
              "       [0.03365631, 0.03365631, 0.03365631, ..., 0.03365631, 0.03365631,\n",
              "        0.03365631],\n",
              "       [0.25184095, 0.0366096 , 0.0366096 , ..., 0.0366096 , 0.0366096 ,\n",
              "        0.0366096 ],\n",
              "       ...,\n",
              "       [0.26687206, 0.02914502, 0.02914502, ..., 0.13007484, 0.02916018,\n",
              "        0.28739608],\n",
              "       [0.10378115, 0.02637829, 0.12325014, ..., 0.02637829, 0.02637829,\n",
              "        0.02637829],\n",
              "       [0.03376055, 0.03376055, 0.2255442 , ..., 0.03376055, 0.03376055,\n",
              "        0.03376055]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNX8PmjTEGk0",
        "outputId": "dcd1b335-1007-4961-af01-e91ecaa8918f"
      },
      "source": [
        "print(np.shape(lda_model.components_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRBHEx8uFHb1"
      },
      "source": [
        "# LDA의 결과 토픽과 각 단어의 비중을 출력하자\n",
        "def get_topics(components, feature_names, n=5):\n",
        "  for idx, topic in enumerate(components):\n",
        "    print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n - 1:-1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWKh_t3IHLcb",
        "outputId": "e1d0c1a7-fb30-4c72-b61b-f55fb3566e0f"
      },
      "source": [
        "get_topics(lda_model.components_, terms)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 1: [('australia', 9359.06334), ('sydney', 5854.97288), ('attack', 4784.76322), ('change', 4193.63035), ('year', 3924.88997)]\n",
            "Topic 2: [('government', 6344.07413), ('charge', 5947.12292), ('man', 4519.7974), ('state', 3658.16422), ('live', 3625.10473)]\n",
            "Topic 3: [('australian', 7666.65651), ('say', 7561.01807), ('police', 5513.22932), ('home', 4048.38409), ('report', 3796.04446)]\n",
            "Topic 4: [('melbourne', 5298.35047), ('south', 4844.59835), ('death', 4281.78433), ('china', 3214.44581), ('women', 3029.28443)]\n",
            "Topic 5: [('win', 5704.0914), ('canberra', 4322.0963), ('die', 4025.63057), ('open', 3771.65243), ('warn', 3577.47151)]\n",
            "Topic 6: [('court', 5246.3124), ('world', 4536.86331), ('country', 4166.34794), ('woman', 3983.97748), ('crash', 3793.50267)]\n",
            "Topic 7: [('election', 5418.5038), ('adelaide', 4864.95604), ('house', 4478.6135), ('school', 3966.82676), ('2016', 3955.11155)]\n",
            "Topic 8: [('trump', 8189.58575), ('new', 6625.2724), ('north', 3705.40987), ('rural', 3521.42659), ('donald', 3356.26657)]\n",
            "Topic 9: [('perth', 4552.8151), ('kill', 4093.61782), ('break', 2695.71958), ('budget', 2596.93268), ('children', 2586.01957)]\n",
            "Topic 10: [('queensland', 5552.68506), ('coast', 3825.32603), ('tasmanian', 3550.75997), ('shoot', 3185.71575), ('service', 2695.21462)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ahhImbXHSiz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}