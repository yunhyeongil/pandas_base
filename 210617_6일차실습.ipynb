{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "210617_6일차실습.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yunhyeongil/pandas_base/blob/main/210617_6%EC%9D%BC%EC%B0%A8%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNjUTeBAXT1t"
      },
      "source": [
        "# '경마장에 말이 달리고 있다'\n",
        "# 경마장에\n",
        "# 말이\n",
        "# 달리고\n",
        "# 있다\n",
        "\n",
        "# 글자단위\n",
        "# 경\n",
        "# 마\n",
        "# 장\n",
        "# 에\n",
        "# 말\n",
        "# 이\n",
        "# 달\n",
        "# 리\n",
        "# 고 \n",
        "# 있\n",
        "# 다"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2bSrSK6Xv4h"
      },
      "source": [
        "## 글자 단위 RNN 언어 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmA71LaJeuKw"
      },
      "source": [
        "![r](https://wikidocs.net/images/page/48649/char_rnn1.PNG)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuSPKSVUXsoJ"
      },
      "source": [
        "import numpy as np\n",
        "import urllib.request\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf59iGfwYBJO",
        "outputId": "f3d034c0-23ab-4ae9-e766-acfe201b0b65"
      },
      "source": [
        "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\"11-0.txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('11-0.txt', <http.client.HTTPMessage at 0x7f5b3c409590>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGrYq6UeYErL"
      },
      "source": [
        "f = open('11-0.txt', 'rb')\n",
        "lines = []\n",
        "for line in f:\n",
        "  line = line.strip() # strip을 통해 \\r, \\n을 제거\n",
        "  line = line.lower() # 소문자화 \n",
        "  line = line.decode('ascii', 'ignore') # \\we2\\x80\\x99등과 같은 바이트 열 제거\n",
        "  if len(line)>0:\n",
        "    lines.append(line)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja_VXqepYWhc",
        "outputId": "748aef50-d16a-4aa0-bb87-68757ecc341a"
      },
      "source": [
        "lines[:5] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the project gutenberg ebook of alices adventures in wonderland, by lewis carroll',\n",
              " 'this ebook is for the use of anyone anywhere in the united states and',\n",
              " 'most other parts of the world at no cost and with almost no restrictions',\n",
              " 'whatsoever. you may copy it, give it away or re-use it under the terms',\n",
              " 'of the project gutenberg license included with this ebook or online at']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJjOdP2_Ymmp",
        "outputId": "b9d1007c-353c-44cb-e68e-5c423340db16"
      },
      "source": [
        "text = ' '.join(lines)\n",
        "print('문자열의 길이 또는 총 글자의 갯수 : %d' %len(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문자열의 길이 또는 총 글자의 갯수 : 159484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJWctfvNYz4s",
        "outputId": "96c6f6f9-cbc0-405e-9821-98ca062a06b0"
      },
      "source": [
        "print(text[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the projec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6McfHHulY2d5",
        "outputId": "2a58e9e9-f2d9-4f34-f301-27e15e7ad740"
      },
      "source": [
        "# 글자 집합을 만들어보자\n",
        "char_vocab = sorted(list(set(text)))\n",
        "vocab_size = len(char_vocab)\n",
        "print('글자 집합의 크기 : {}'.format(vocab_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "글자 집합의 크기 : 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLYdFZH_ZRR5",
        "outputId": "f754e6b8-7fbf-443b-ad25-c5d18e640786"
      },
      "source": [
        "print(char_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ', '!', '\"', '#', '$', '%', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQtkE7YPZYQh",
        "outputId": "e9b6b063-8c50-4629-ea9c-ca9c80cc58ef"
      },
      "source": [
        "# 글자 집합에 인덱스를 부여하고 전부 출력하기\n",
        "char_to_index = dict((c, i) for i, c in enumerate(char_vocab))\n",
        "print(char_to_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 0, '!': 1, '\"': 2, '#': 3, '$': 4, '%': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, '[': 27, ']': 28, '_': 29, 'a': 30, 'b': 31, 'c': 32, 'd': 33, 'e': 34, 'f': 35, 'g': 36, 'h': 37, 'i': 38, 'j': 39, 'k': 40, 'l': 41, 'm': 42, 'n': 43, 'o': 44, 'p': 45, 'q': 46, 'r': 47, 's': 48, 't': 49, 'u': 50, 'v': 51, 'w': 52, 'x': 53, 'y': 54, 'z': 55}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI0eXLi0ZvZ5"
      },
      "source": [
        "# 인덱스로부터 글자를 리턴하기\n",
        "index_to_char = {}\n",
        "for key, value in char_to_index.items():\n",
        "  index_to_char[value] = key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HrttPtgaLJh",
        "outputId": "8f8ff3fa-db0d-4c22-d0bc-fff656f6dee1"
      },
      "source": [
        "print(index_to_char)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: ' ', 1: '!', 2: '\"', 3: '#', 4: '$', 5: '%', 6: \"'\", 7: '(', 8: ')', 9: '*', 10: ',', 11: '-', 12: '.', 13: '/', 14: '0', 15: '1', 16: '2', 17: '3', 18: '4', 19: '5', 20: '6', 21: '7', 22: '8', 23: '9', 24: ':', 25: ';', 26: '?', 27: '[', 28: ']', 29: '_', 30: 'a', 31: 'b', 32: 'c', 33: 'd', 34: 'e', 35: 'f', 36: 'g', 37: 'h', 38: 'i', 39: 'j', 40: 'k', 41: 'l', 42: 'm', 43: 'n', 44: 'o', 45: 'p', 46: 'q', 47: 'r', 48: 's', 49: 't', 50: 'u', 51: 'v', 52: 'w', 53: 'x', 54: 'y', 55: 'z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTUIjzVnaPNR"
      },
      "source": [
        "# 훈련데이터를 구성\n",
        "# apple \n",
        "# sample의 길이 4\n",
        "\n",
        "# example) 샘플의 길이가 4라면 4개의 입력 글자 시퀀스로부터 4개의 출력 글자 시퀀스 예측. 즉 RNN의 time step은 4번\n",
        "# appl -> pple\n",
        "# appl (입력시퀀스, train_x), pple(예측해야하는 시퀀스, train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmZZC8Ysa0Oi",
        "outputId": "6b9887e8-dbf5-424c-8fe7-6b11f8e74352"
      },
      "source": [
        "# 15만 8천의 길이를 가진 text문자열로부터 다수의 문장 샘플들로 분리\n",
        "# 분리하는 방법은 문장 샘플의 길이를 정하고, 해당 길이만큼 문자열 전부를 전부 등분 하는 것!!\n",
        "seq_length = 60\n",
        "n_samples = int(np.floor((len(text)-1)/seq_length)) #문자열을 60등분한다 ---> 총 샘플의 수\n",
        "print('문장 샘플의 수 : {}'.format(n_samples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문장 샘플의 수 : 2658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLk2ZvBLbEqS"
      },
      "source": [
        "train_x = []\n",
        "train_y = []\n",
        "\n",
        "for i in range(n_samples): # 2658번 수행\n",
        "  x_sample = text[i * seq_length: (i+1)*seq_length] # 문장 샘플을 1개씩 가져온다.\n",
        "  x_encoded = [char_to_index[c] for c in x_sample] # 하나의 문장 샘플에 대해서 정수 인코딩\n",
        "  train_x.append(x_encoded)\n",
        "\n",
        "  y_sample = text[i*seq_length + 1: (i+1) *seq_length + 1] # 오른쪽으로 1칸 쉬프트한다.\n",
        "  y_encoded = [char_to_index[c] for c in y_sample]\n",
        "  train_y.append(y_encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lg_pIxxncFew",
        "outputId": "d6a1e67e-4596-4dc9-f005-8b0af6c7c4c9"
      },
      "source": [
        "print(train_x[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[49, 37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY_PA-F1cbXZ",
        "outputId": "a1fee4f4-84de-4ba6-edc7-9360763a3187"
      },
      "source": [
        "print(train_y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30, 43]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHWnAJCHcdnX",
        "outputId": "c999a0f4-061f-4c84-d1a3-02c2b65e7c27"
      },
      "source": [
        "print(train_x[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[43, 33, 10, 0, 31, 54, 0, 41, 34, 52, 38, 48, 0, 32, 30, 47, 47, 44, 41, 41, 0, 49, 37, 38, 48, 0, 34, 31, 44, 44, 40, 0, 38, 48, 0, 35, 44, 47, 0, 49, 37, 34, 0, 50, 48, 34, 0, 44, 35, 0, 30, 43, 54, 44, 43, 34, 0, 30, 43, 54]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q2oXU2rcgQX",
        "outputId": "5ebee37d-1dc2-4a51-eee5-d1dd60659d79"
      },
      "source": [
        "print(train_y[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[33, 10, 0, 31, 54, 0, 41, 34, 52, 38, 48, 0, 32, 30, 47, 47, 44, 41, 41, 0, 49, 37, 38, 48, 0, 34, 31, 44, 44, 40, 0, 38, 48, 0, 35, 44, 47, 0, 49, 37, 34, 0, 50, 48, 34, 0, 44, 35, 0, 30, 43, 54, 44, 43, 34, 0, 30, 43, 54, 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNkXPOm8ckOw"
      },
      "source": [
        "# x와 y에 대해 원-핫 인코딩 수행. 입력시퀀스에 대해 워드 임베딩 하지 않습니다 -> embedding layer사용 X\n",
        "train_x = to_categorical(train_x)\n",
        "train_y = to_categorical(train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aClTGUhXiIvQ",
        "outputId": "7bf79f71-6ba5-4a05-e3d5-40e43bdf43ec"
      },
      "source": [
        "print('train_x의 크기 (shape) : {}'.format(train_x.shape))\n",
        "print('train_y의 크기 (shape) : {}'.format(train_y.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_x의 크기 (shape) : (2658, 60, 56)\n",
            "train_y의 크기 (shape) : (2658, 60, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFkK44WAid-3"
      },
      "source": [
        "샘플의 수가 2658, 입력시퀀스의 길이(input_length) 60, 각 벡터의 차원(input_dim) 56 의미  \n",
        "원-핫 벡터의 차원은 글자 집합의 크기인 56"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-lo12T_iwQY"
      },
      "source": [
        "![](https://wikidocs.net/images/page/22886/rnn_image6between7.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSmegAxQiyb3"
      },
      "source": [
        "### 모델 설계하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv0KB_itiUB3"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK-XXvF6i-N3"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(None, train_x.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(256, return_sequences=True)) #\n",
        "model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXmbzav3jNeP",
        "outputId": "03b8a157-da2e-4cd1-e9ae-aaa85f587275"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
        "model.fit(train_x, train_y, epochs=80, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "84/84 [==============================] - 10s 12ms/step - loss: 3.0742 - accuracy: 0.1821\n",
            "Epoch 2/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.7314 - accuracy: 0.2471\n",
            "Epoch 3/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.3968 - accuracy: 0.3268\n",
            "Epoch 4/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.2570 - accuracy: 0.3598\n",
            "Epoch 5/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.1469 - accuracy: 0.3873\n",
            "Epoch 6/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.0626 - accuracy: 0.4068\n",
            "Epoch 7/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.9965 - accuracy: 0.4236\n",
            "Epoch 8/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.9395 - accuracy: 0.4394\n",
            "Epoch 9/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.8887 - accuracy: 0.4528\n",
            "Epoch 10/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.8404 - accuracy: 0.4665\n",
            "Epoch 11/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.7930 - accuracy: 0.4793\n",
            "Epoch 12/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.7484 - accuracy: 0.4918\n",
            "Epoch 13/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.7100 - accuracy: 0.5014\n",
            "Epoch 14/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.6721 - accuracy: 0.5113\n",
            "Epoch 15/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.6341 - accuracy: 0.5205\n",
            "Epoch 16/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.6010 - accuracy: 0.5293\n",
            "Epoch 17/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.5716 - accuracy: 0.5374\n",
            "Epoch 18/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.5373 - accuracy: 0.5457\n",
            "Epoch 19/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.5052 - accuracy: 0.5542\n",
            "Epoch 20/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.4787 - accuracy: 0.5614\n",
            "Epoch 21/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.4462 - accuracy: 0.5707\n",
            "Epoch 22/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.4166 - accuracy: 0.5794\n",
            "Epoch 23/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.3916 - accuracy: 0.5871\n",
            "Epoch 24/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.3617 - accuracy: 0.5947\n",
            "Epoch 25/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.3353 - accuracy: 0.6021\n",
            "Epoch 26/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.3054 - accuracy: 0.6115\n",
            "Epoch 27/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2783 - accuracy: 0.6185\n",
            "Epoch 28/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2523 - accuracy: 0.6269\n",
            "Epoch 29/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.2227 - accuracy: 0.6348\n",
            "Epoch 30/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.1959 - accuracy: 0.6428\n",
            "Epoch 31/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.1684 - accuracy: 0.6503\n",
            "Epoch 32/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.1412 - accuracy: 0.6585\n",
            "Epoch 33/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.1161 - accuracy: 0.6654\n",
            "Epoch 34/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.0871 - accuracy: 0.6751\n",
            "Epoch 35/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.0582 - accuracy: 0.6835\n",
            "Epoch 36/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.0325 - accuracy: 0.6917\n",
            "Epoch 37/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.0034 - accuracy: 0.7005\n",
            "Epoch 38/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.9772 - accuracy: 0.7093\n",
            "Epoch 39/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.9544 - accuracy: 0.7156\n",
            "Epoch 40/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.9241 - accuracy: 0.7246\n",
            "Epoch 41/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.8904 - accuracy: 0.7363\n",
            "Epoch 42/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.8676 - accuracy: 0.7423\n",
            "Epoch 43/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.8449 - accuracy: 0.7494\n",
            "Epoch 44/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.8152 - accuracy: 0.7593\n",
            "Epoch 45/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.7851 - accuracy: 0.7692\n",
            "Epoch 46/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.7669 - accuracy: 0.7740\n",
            "Epoch 47/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.7355 - accuracy: 0.7852\n",
            "Epoch 48/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.7164 - accuracy: 0.7907\n",
            "Epoch 49/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.6998 - accuracy: 0.7958\n",
            "Epoch 50/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.6684 - accuracy: 0.8063\n",
            "Epoch 51/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.6379 - accuracy: 0.8166\n",
            "Epoch 52/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.6226 - accuracy: 0.8205\n",
            "Epoch 53/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.5962 - accuracy: 0.8297\n",
            "Epoch 54/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.5753 - accuracy: 0.8354\n",
            "Epoch 55/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.5636 - accuracy: 0.8385\n",
            "Epoch 56/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.5327 - accuracy: 0.8493\n",
            "Epoch 57/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.5212 - accuracy: 0.8527\n",
            "Epoch 58/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.4935 - accuracy: 0.8631\n",
            "Epoch 59/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.4764 - accuracy: 0.8680\n",
            "Epoch 60/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.4503 - accuracy: 0.8775\n",
            "Epoch 61/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.4408 - accuracy: 0.8792\n",
            "Epoch 62/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.4247 - accuracy: 0.8838\n",
            "Epoch 63/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.4074 - accuracy: 0.8895\n",
            "Epoch 64/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.3935 - accuracy: 0.8948\n",
            "Epoch 65/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.4047 - accuracy: 0.8887\n",
            "Epoch 66/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.3729 - accuracy: 0.8998\n",
            "Epoch 67/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.3453 - accuracy: 0.9105\n",
            "Epoch 68/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.3452 - accuracy: 0.9091\n",
            "Epoch 69/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.3189 - accuracy: 0.9186\n",
            "Epoch 70/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.3023 - accuracy: 0.9243\n",
            "Epoch 71/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.2845 - accuracy: 0.9305\n",
            "Epoch 72/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.2717 - accuracy: 0.9347\n",
            "Epoch 73/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.2682 - accuracy: 0.9343\n",
            "Epoch 74/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.2561 - accuracy: 0.9384\n",
            "Epoch 75/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.2517 - accuracy: 0.9386\n",
            "Epoch 76/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.2421 - accuracy: 0.9416\n",
            "Epoch 77/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.2350 - accuracy: 0.9436\n",
            "Epoch 78/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.2338 - accuracy: 0.9432\n",
            "Epoch 79/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.2177 - accuracy: 0.9485\n",
            "Epoch 80/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.2202 - accuracy: 0.9465\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5a9cebec10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxXC016XjhBG"
      },
      "source": [
        "def sentence_generation(model, length):\n",
        "    ix = [np.random.randint(vocab_size)] # 글자에 대한 랜덤 인덱스 생성\n",
        "    y_char = [index_to_char[ix[-1]]] # 랜덤 익덱스로부터 글자 생성\n",
        "    print(ix[-1],'번 글자',y_char[-1],'로 예측을 시작!')\n",
        "    X = np.zeros((1, length, vocab_size)) # (1, length, 55) 크기의 X 생성. 즉, LSTM의 입력 시퀀스 생성\n",
        "\n",
        "    for i in range(length):\n",
        "        X[0][i][ix[-1]] = 1 # X[0][i][예측한 글자의 인덱스] = 1, 즉, 예측 글자를 다음 입력 시퀀스에 추가\n",
        "        print(index_to_char[ix[-1]], end=\"\")\n",
        "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
        "        y_char.append(index_to_char[ix[-1]])\n",
        "    return ('').join(y_char)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "7FtpeXvHoEyY",
        "outputId": "8a58cdd6-e39d-4d27-9201-5a56e3b1be03"
      },
      "source": [
        "sentence_generation(model, 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36 번 글자 g 로 예측을 시작!\n",
            "g her very much of a well! the dormouse again to them to do it? hald do at eles! the words draw _net"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'g her very much of a well! the dormouse again to them to do it? hald do at eles! the words draw _net '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "pRzkT6vGoJa-",
        "outputId": "b8080d57-966d-4897-c534-db653b80e292"
      },
      "source": [
        "sentence_generation(model, 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 번 글자   로 예측을 시작!\n",
            " a little notter to maky the s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' a little notter to maky the si'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "vtcMv3rroj_-",
        "outputId": "5a01d1f4-4521-4258-8b24-2f166700d8ae"
      },
      "source": [
        "sentence_generation(model, 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36 번 글자 g 로 예측을 시작!\n",
            "g her very much of a well! the dormouse again to them to do it? hald do at eles! the words draw _net"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'g her very much of a well! the dormouse again to them to do it? hald do at eles! the words draw _net '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "iEXCRxlXooUG",
        "outputId": "b845fb12-d448-4c71-ce7b-f05bb49dec90"
      },
      "source": [
        "sentence_generation(model, 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55 번 글자 z 로 예측을 시작!\n",
            "zard) could not make out "
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'zard) could not make out a'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSbs5HTLtVym"
      },
      "source": [
        "## 글자 단위 RNN(Char RNN)으로 텍스트 생성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvwDAgOktcmF"
      },
      "source": [
        "다 대 일(many to one)구조의 RNN을 글자 단위로 학습시키고, 텍스트 생성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmYJ_DF2tjvt"
      },
      "source": [
        "### 데이터에 대한 이해와 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi4JXJvDorWe"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4VRiFRTttn-"
      },
      "source": [
        "text='''\n",
        "I get on with life as a programmer,\n",
        "I like to contemplate beer.\n",
        "But when I start to daydream,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "Do I love wine more than beer?\n",
        "\n",
        "I like to use words about beer.\n",
        "But when I stop my talking,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "I hate bugs and errors.\n",
        "But I just think back to wine,\n",
        "And I'm happy once again.\n",
        "\n",
        "I like to hang out with programming and deep learning.\n",
        "But when left alone,\n",
        "My mind turns straight to wine.\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow1U4RuOt4s0",
        "outputId": "7e335991-0a22-43da-a3c0-a305042c73f7"
      },
      "source": [
        "tokens = text.split() # '\\n 제거'\n",
        "text = ' '.join(tokens)\n",
        "print(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I get on with life as a programmer, I like to contemplate beer. But when I start to daydream, My mind turns straight to wine. Do I love wine more than beer? I like to use words about beer. But when I stop my talking, My mind turns straight to wine. I hate bugs and errors. But I just think back to wine, And I'm happy once again. I like to hang out with programming and deep learning. But when left alone, My mind turns straight to wine.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPIJ0B4SuMuN",
        "outputId": "4cd26dcd-ab8d-4c06-822c-dfed33175e1b"
      },
      "source": [
        "char_vocab = sorted(list(set(text))) #중복을 제거한 글자 집합 생성\n",
        "print(char_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ', \"'\", ',', '.', '?', 'A', 'B', 'D', 'I', 'M', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4BMQVoLuds1",
        "outputId": "fd5b4a2f-b24d-4034-b8ed-0e3fc3de239b"
      },
      "source": [
        "vocab_size = len(char_vocab)\n",
        "print('글자 집합의 크기 : {}'.format(vocab_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "글자 집합의 크기 : 33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UUAg7lDuq0d",
        "outputId": "0042969d-fd88-4eb1-8de2-1ccf9311cba5"
      },
      "source": [
        "char_to_index = dict((c, i) for i,c in enumerate(char_vocab)) # 글자에 고유한 정수 인덱스 부여\n",
        "print(char_to_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 0, \"'\": 1, ',': 2, '.': 3, '?': 4, 'A': 5, 'B': 6, 'D': 7, 'I': 8, 'M': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14, 'f': 15, 'g': 16, 'h': 17, 'i': 18, 'j': 19, 'k': 20, 'l': 21, 'm': 22, 'n': 23, 'o': 24, 'p': 25, 'r': 26, 's': 27, 't': 28, 'u': 29, 'v': 30, 'w': 31, 'y': 32}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Lx2tU3xu_at"
      },
      "source": [
        "example 5개의 입력 글자 시퀀스로부터 다음 글자 시퀀스를 예측 \n",
        "\n",
        "- stude -> n  \n",
        "- tuden -> t  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibFR3--6u0Jt",
        "outputId": "b59c4cfe-8e74-4dbc-a7ea-3fa17db2eac8"
      },
      "source": [
        "length = 11\n",
        "sequences = []\n",
        "for i in range(length, len(text)):\n",
        "  seq = text[i-length:i] # 길이 11의 문자열을 지속적으로 만듬\n",
        "  sequences.append(seq)\n",
        "\n",
        "print('총 훈련 샘플의 수: %d' %len(sequences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "총 훈련 샘플의 수: 426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiOaUTpIvi9W",
        "outputId": "d9498806-1739-4ed8-df66-6edee832e6da"
      },
      "source": [
        "print(sequences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I get on wi', ' get on wit', 'get on with', 'et on with ', 't on with l', ' on with li', 'on with lif', 'n with life', ' with life ', 'with life a', 'ith life as', 'th life as ', 'h life as a', ' life as a ', 'life as a p', 'ife as a pr', 'fe as a pro', 'e as a prog', ' as a progr', 'as a progra', 's a program', ' a programm', 'a programme', ' programmer', 'programmer,', 'rogrammer, ', 'ogrammer, I', 'grammer, I ', 'rammer, I l', 'ammer, I li', 'mmer, I lik', 'mer, I like', 'er, I like ', 'r, I like t', ', I like to', ' I like to ', 'I like to c', ' like to co', 'like to con', 'ike to cont', 'ke to conte', 'e to contem', ' to contemp', 'to contempl', 'o contempla', ' contemplat', 'contemplate', 'ontemplate ', 'ntemplate b', 'template be', 'emplate bee', 'mplate beer', 'plate beer.', 'late beer. ', 'ate beer. B', 'te beer. Bu', 'e beer. But', ' beer. But ', 'beer. But w', 'eer. But wh', 'er. But whe', 'r. But when', '. But when ', ' But when I', 'But when I ', 'ut when I s', 't when I st', ' when I sta', 'when I star', 'hen I start', 'en I start ', 'n I start t', ' I start to', 'I start to ', ' start to d', 'start to da', 'tart to day', 'art to dayd', 'rt to daydr', 't to daydre', ' to daydrea', 'to daydream', 'o daydream,', ' daydream, ', 'daydream, M', 'aydream, My', 'ydream, My ', 'dream, My m', 'ream, My mi', 'eam, My min', 'am, My mind', 'm, My mind ', ', My mind t', ' My mind tu', 'My mind tur', 'y mind turn', ' mind turns', 'mind turns ', 'ind turns s', 'nd turns st', 'd turns str', ' turns stra', 'turns strai', 'urns straig', 'rns straigh', 'ns straight', 's straight ', ' straight t', 'straight to', 'traight to ', 'raight to w', 'aight to wi', 'ight to win', 'ght to wine', 'ht to wine.', 't to wine. ', ' to wine. D', 'to wine. Do', 'o wine. Do ', ' wine. Do I', 'wine. Do I ', 'ine. Do I l', 'ne. Do I lo', 'e. Do I lov', '. Do I love', ' Do I love ', 'Do I love w', 'o I love wi', ' I love win', 'I love wine', ' love wine ', 'love wine m', 'ove wine mo', 've wine mor', 'e wine more', ' wine more ', 'wine more t', 'ine more th', 'ne more tha', 'e more than', ' more than ', 'more than b', 'ore than be', 're than bee', 'e than beer', ' than beer?', 'than beer? ', 'han beer? I', 'an beer? I ', 'n beer? I l', ' beer? I li', 'beer? I lik', 'eer? I like', 'er? I like ', 'r? I like t', '? I like to', ' I like to ', 'I like to u', ' like to us', 'like to use', 'ike to use ', 'ke to use w', 'e to use wo', ' to use wor', 'to use word', 'o use words', ' use words ', 'use words a', 'se words ab', 'e words abo', ' words abou', 'words about', 'ords about ', 'rds about b', 'ds about be', 's about bee', ' about beer', 'about beer.', 'bout beer. ', 'out beer. B', 'ut beer. Bu', 't beer. But', ' beer. But ', 'beer. But w', 'eer. But wh', 'er. But whe', 'r. But when', '. But when ', ' But when I', 'But when I ', 'ut when I s', 't when I st', ' when I sto', 'when I stop', 'hen I stop ', 'en I stop m', 'n I stop my', ' I stop my ', 'I stop my t', ' stop my ta', 'stop my tal', 'top my talk', 'op my talki', 'p my talkin', ' my talking', 'my talking,', 'y talking, ', ' talking, M', 'talking, My', 'alking, My ', 'lking, My m', 'king, My mi', 'ing, My min', 'ng, My mind', 'g, My mind ', ', My mind t', ' My mind tu', 'My mind tur', 'y mind turn', ' mind turns', 'mind turns ', 'ind turns s', 'nd turns st', 'd turns str', ' turns stra', 'turns strai', 'urns straig', 'rns straigh', 'ns straight', 's straight ', ' straight t', 'straight to', 'traight to ', 'raight to w', 'aight to wi', 'ight to win', 'ght to wine', 'ht to wine.', 't to wine. ', ' to wine. I', 'to wine. I ', 'o wine. I h', ' wine. I ha', 'wine. I hat', 'ine. I hate', 'ne. I hate ', 'e. I hate b', '. I hate bu', ' I hate bug', 'I hate bugs', ' hate bugs ', 'hate bugs a', 'ate bugs an', 'te bugs and', 'e bugs and ', ' bugs and e', 'bugs and er', 'ugs and err', 'gs and erro', 's and error', ' and errors', 'and errors.', 'nd errors. ', 'd errors. B', ' errors. Bu', 'errors. But', 'rrors. But ', 'rors. But I', 'ors. But I ', 'rs. But I j', 's. But I ju', '. But I jus', ' But I just', 'But I just ', 'ut I just t', 't I just th', ' I just thi', 'I just thin', ' just think', 'just think ', 'ust think b', 'st think ba', 't think bac', ' think back', 'think back ', 'hink back t', 'ink back to', 'nk back to ', 'k back to w', ' back to wi', 'back to win', 'ack to wine', 'ck to wine,', 'k to wine, ', ' to wine, A', 'to wine, An', 'o wine, And', ' wine, And ', 'wine, And I', \"ine, And I'\", \"ne, And I'm\", \"e, And I'm \", \", And I'm h\", \" And I'm ha\", \"And I'm hap\", \"nd I'm happ\", \"d I'm happy\", \" I'm happy \", \"I'm happy o\", \"'m happy on\", 'm happy onc', ' happy once', 'happy once ', 'appy once a', 'ppy once ag', 'py once aga', 'y once agai', ' once again', 'once again.', 'nce again. ', 'ce again. I', 'e again. I ', ' again. I l', 'again. I li', 'gain. I lik', 'ain. I like', 'in. I like ', 'n. I like t', '. I like to', ' I like to ', 'I like to h', ' like to ha', 'like to han', 'ike to hang', 'ke to hang ', 'e to hang o', ' to hang ou', 'to hang out', 'o hang out ', ' hang out w', 'hang out wi', 'ang out wit', 'ng out with', 'g out with ', ' out with p', 'out with pr', 'ut with pro', 't with prog', ' with progr', 'with progra', 'ith program', 'th programm', 'h programmi', ' programmin', 'programming', 'rogramming ', 'ogramming a', 'gramming an', 'ramming and', 'amming and ', 'mming and d', 'ming and de', 'ing and dee', 'ng and deep', 'g and deep ', ' and deep l', 'and deep le', 'nd deep lea', 'd deep lear', ' deep learn', 'deep learni', 'eep learnin', 'ep learning', 'p learning.', ' learning. ', 'learning. B', 'earning. Bu', 'arning. But', 'rning. But ', 'ning. But w', 'ing. But wh', 'ng. But whe', 'g. But when', '. But when ', ' But when l', 'But when le', 'ut when lef', 't when left', ' when left ', 'when left a', 'hen left al', 'en left alo', 'n left alon', ' left alone', 'left alone,', 'eft alone, ', 'ft alone, M', 't alone, My', ' alone, My ', 'alone, My m', 'lone, My mi', 'one, My min', 'ne, My mind', 'e, My mind ', ', My mind t', ' My mind tu', 'My mind tur', 'y mind turn', ' mind turns', 'mind turns ', 'ind turns s', 'nd turns st', 'd turns str', ' turns stra', 'turns strai', 'urns straig', 'rns straigh', 'ns straight', 's straight ', ' straight t', 'straight to', 'traight to ', 'raight to w', 'aight to wi', 'ight to win', 'ght to wine']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgcPFmjUvmnK"
      },
      "source": [
        "xx = []\n",
        "for line in sequences: #전체 데이터에서 문장 샘플을 1개씩 꺼냄\n",
        "  temp_x = [char_to_index[char] for char in line] # 문장 샘플에서 각 글자에 대해서 정수 인코딩 수행\n",
        "  xx.append(temp_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seHcLqvFwA80",
        "outputId": "d6f04802-00b6-4df2-ce17-a13920b1f0a5"
      },
      "source": [
        "for line in xx[:5]:\n",
        "  print(line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8, 0, 16, 14, 28, 0, 24, 23, 0, 31, 18]\n",
            "[0, 16, 14, 28, 0, 24, 23, 0, 31, 18, 28]\n",
            "[16, 14, 28, 0, 24, 23, 0, 31, 18, 28, 17]\n",
            "[14, 28, 0, 24, 23, 0, 31, 18, 28, 17, 0]\n",
            "[28, 0, 24, 23, 0, 31, 18, 28, 17, 0, 21]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf-GZXI4wDgd"
      },
      "source": [
        "sequences = np.array(xx)\n",
        "xx = sequences[:, :-1]\n",
        "y = sequences[:, -1] # 맨 마지막 위치의 글자를 분리"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuhMSa2DwdWn",
        "outputId": "183bf11a-278f-4373-e7b7-fd01b883057f"
      },
      "source": [
        "for line in xx[:5]:\n",
        "  print(line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 8  0 16 14 28  0 24 23  0 31]\n",
            "[ 0 16 14 28  0 24 23  0 31 18]\n",
            "[16 14 28  0 24 23  0 31 18 28]\n",
            "[14 28  0 24 23  0 31 18 28 17]\n",
            "[28  0 24 23  0 31 18 28 17  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrZ-4C38whGc",
        "outputId": "78a72be4-c62c-4b35-827c-926ad12c2f3e"
      },
      "source": [
        "print(y[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18 28 17  0 21]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmr1cmeNwuJ8"
      },
      "source": [
        "### 원-핫 인코딩 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXbs99qRwof8"
      },
      "source": [
        "sequences = [to_categorical(x, num_classes=vocab_size) for x in xx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7sWuEtRw8sM"
      },
      "source": [
        "x = np.array(sequences)\n",
        "y = to_categorical(y, num_classes=vocab_size) # y에 대한 원-핫 인코딩"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFbBgTOPxEiE",
        "outputId": "ec87017d-25c8-4966-ae54-64eabf0260f4"
      },
      "source": [
        "print(x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(426, 10, 33)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhMq4L5eyOyM"
      },
      "source": [
        "- 샘플의 수 426  \n",
        "- 입력시퀀스의 길이 10  \n",
        "- 각 벡터의 차원 33  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LlfoPYZyY_T"
      },
      "source": [
        "### 모델 설계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RVRjBJHxFe0"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6ythR2yyonM"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(x.shape[1], x.shape[2]))) # (10, 33)\n",
        "model.add(Dense(vocab_size, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKdwlTBMy6U8",
        "outputId": "c2c339df-0a9b-4b43-c0a4-e2c4a0adbdeb"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
        "model.fit(x, y, epochs=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "14/14 [==============================] - 8s 5ms/step - loss: 3.4579 - accuracy: 0.1315\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 3.2014 - accuracy: 0.1972\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 3.0022 - accuracy: 0.1972\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.9647 - accuracy: 0.1972\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 2.9530 - accuracy: 0.1972\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.9398 - accuracy: 0.1972\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.9148 - accuracy: 0.1972\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.8889 - accuracy: 0.1972\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.8542 - accuracy: 0.1972\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.7952 - accuracy: 0.1972\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.7243 - accuracy: 0.2160\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.6490 - accuracy: 0.2324\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.6065 - accuracy: 0.2512\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.5144 - accuracy: 0.2535\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.4420 - accuracy: 0.2793\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.4201 - accuracy: 0.3052\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.3190 - accuracy: 0.3169\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.2327 - accuracy: 0.3732\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.1456 - accuracy: 0.3638\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.0936 - accuracy: 0.3944\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.0213 - accuracy: 0.4202\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 1.9471 - accuracy: 0.4601\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.8897 - accuracy: 0.4601\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.8153 - accuracy: 0.5023\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.7878 - accuracy: 0.4953\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.7244 - accuracy: 0.5047\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.6414 - accuracy: 0.5634\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.5712 - accuracy: 0.5516\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.4915 - accuracy: 0.5939\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.4488 - accuracy: 0.6056\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 1.3999 - accuracy: 0.6009\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.3417 - accuracy: 0.6526\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.2745 - accuracy: 0.6690\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.2273 - accuracy: 0.6620\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.1589 - accuracy: 0.6925\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.1029 - accuracy: 0.7019\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.0540 - accuracy: 0.7347\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.0037 - accuracy: 0.7512\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.9452 - accuracy: 0.7653\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.9312 - accuracy: 0.7653\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.8875 - accuracy: 0.7723\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.8266 - accuracy: 0.7981\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.7712 - accuracy: 0.8099\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.7407 - accuracy: 0.8474\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.8732\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6461 - accuracy: 0.8662\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.8662\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.5857 - accuracy: 0.8897\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.9061\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.9202\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.9108\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.9319\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.9413\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.9413\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3882 - accuracy: 0.9413\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3665 - accuracy: 0.9413\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3407 - accuracy: 0.9577\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.9531\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3085 - accuracy: 0.9577\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2765 - accuracy: 0.9695\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2644 - accuracy: 0.9718\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2540 - accuracy: 0.9648\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2450 - accuracy: 0.9718\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2362 - accuracy: 0.9624\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2101 - accuracy: 0.9765\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2089 - accuracy: 0.9742\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1935 - accuracy: 0.9789\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1847 - accuracy: 0.9765\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1742 - accuracy: 0.9765\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1665 - accuracy: 0.9765\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1599 - accuracy: 0.9765\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1509 - accuracy: 0.9765\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1594 - accuracy: 0.9718\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1501 - accuracy: 0.9765\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9812\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1410 - accuracy: 0.9742\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9765\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1273 - accuracy: 0.9718\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1226 - accuracy: 0.9812\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1205 - accuracy: 0.9836\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1245 - accuracy: 0.9812\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1282 - accuracy: 0.9742\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1079 - accuracy: 0.9789\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1149 - accuracy: 0.9765\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1209 - accuracy: 0.9718\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1089 - accuracy: 0.9765\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1144 - accuracy: 0.9789\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0992 - accuracy: 0.9812\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0955 - accuracy: 0.9836\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0929 - accuracy: 0.9789\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0895 - accuracy: 0.9812\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0859 - accuracy: 0.9812\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0920 - accuracy: 0.9789\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0869 - accuracy: 0.9812\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0966 - accuracy: 0.9765\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1041 - accuracy: 0.9789\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0931 - accuracy: 0.9812\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1045 - accuracy: 0.9765\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0907 - accuracy: 0.9836\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0850 - accuracy: 0.9812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fca3010ffd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z32ujx4JzRFD"
      },
      "source": [
        "def sentence_generation(model, char_to_index, seq_length, seed_text, n):\n",
        "  # 모델, 인덱스 정보, 문장 길이, 초기 시퀀스, 반복 횟수\n",
        "\n",
        "  init_text = seed_text #문장 생성에 사용할 초기 시퀀스\n",
        "  sentence = ''\n",
        "\n",
        "  for _ in range(n): # n번 반복\n",
        "    encoded = [char_to_index[char] for char in seed_text] #현재 시퀀스에 대한 정수 인코딩\n",
        "    encoded = pad_sequences([encoded], maxlen=seq_length, padding='pre') #데이터에 대한 패딩\n",
        "    encoded = to_categorical(encoded, num_classes=len(char_to_index))\n",
        "    result = model.predict_classes(encoded, verbose=0)\n",
        "    #입력한 x(현재 시퀀스)에 대해서 y를 예측하고 y(예측한 글자)를 result에 저장\n",
        "\n",
        "    for char, index in char_to_index.items(): #만약 예측한 글자와 인덱스와 동일한 글자가 있다면\n",
        "      if index == result: #해당 글자가 예측 글자이므로 break\n",
        "        break\n",
        "    \n",
        "    seed_text = seed_text + char # 현재 시퀀스 + 예측 글자를 현재 시퀀스에 변경\n",
        "    sentence = sentence + char # 예측 글자를 문장에 저장\n",
        "\n",
        "  sentence = init_text + sentence\n",
        "  return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTIOp2RI1Jx7",
        "outputId": "90377109-8c11-47fd-f4ba-b166524be13f"
      },
      "source": [
        "print(sentence_generation(model, char_to_index, 10, 'I get on w', 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "I get on with life as a programmer, I like to use words about beer. But when I start to daydream, My mind turn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8O0yo8E1YGT",
        "outputId": "5c167da4-17f7-4937-bdbd-a93bcaa85dbf"
      },
      "source": [
        "print(sentence_generation(model, char_to_index, 10, 'Do I love wine', 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Do I love wine more than beer? I like to use words about beer. But when I start to daydream, My mind turns straigh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNtKOmKXW4C0"
      },
      "source": [
        "## 네이버 쇼핑 리뷰 감성 분석\n",
        "- 총 200,000ro 리뷰로 구성  \n",
        "- 평점이 5점 만점에 1, 2, 4, 5인 리뷰들로 구성\n",
        "- 평점이 4, 5인 리뷰들에 긍정 1, 부정 0\n",
        "- 감성 분류 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ouk96niXZoK",
        "outputId": "944ce453-f6f8-4b09-f30a-0fd730b66d80"
      },
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 91, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 91 (delta 43), reused 22 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (91/91), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RofE7i3yXdTF",
        "outputId": "6643e9d7-0d15-4f46-ca81-eb1868777317"
      },
      "source": [
        "!pwd "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTqO0capXoU0",
        "outputId": "c00b9b35-d5f5-49b5-a562-0ffe947d52c9"
      },
      "source": [
        "cd Mecab-ko-for-Google-Colab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Mecab-ko-for-Google-Colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skcxGjimXqBM",
        "outputId": "445841cf-5791-4dc0-b840-366059ba0e12"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mimages\u001b[0m/                                    LICENSE\n",
            "install_mecab-ko_on_colab190912.sh         README.md\n",
            "install_mecab-ko_on_colab_light_210108.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfcjb_AQXra0",
        "outputId": "90c07932-72cb-438c-ea9a-6aaa762a6c17"
      },
      "source": [
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing konlpy.....\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/88/f817ef1af6f794e8f11313dcd1549de833f4599abcec82746ab5ed086686/JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 33.7MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2021-06-17 06:31:06--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c3:9b0a, 2406:da00:ff00::22c2:513, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=q%2BPG6t2SD1vPYdVKvSlDMNHtNZM%3D&Expires=1623913224&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-06-17 06:31:07--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=q%2BPG6t2SD1vPYdVKvSlDMNHtNZM%3D&Expires=1623913224&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.110.235\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.110.235|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  2.37MB/s    in 0.6s    \n",
            "\n",
            "2021-06-17 06:31:08 (2.37 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2021-06-17 06:32:41--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::6b17:d1f5, 2406:da00:ff00::22c2:513, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=NhcSUcMJEuaSL76rKMyxsOnyf5o%3D&Expires=1623912562&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-06-17 06:32:42--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=NhcSUcMJEuaSL76rKMyxsOnyf5o%3D&Expires=1623912562&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.192.73\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.192.73|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  24.3MB/s    in 2.0s    \n",
            "\n",
            "2021-06-17 06:32:44 (24.3 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEb7EQn1YrJr"
      },
      "source": [
        "from konlpy.tag import Mecab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqBkOqeoXtI8",
        "outputId": "02da8a13-eebf-423f-aea9-02591bf142ef"
      },
      "source": [
        "mecab = Mecab() # mecab 테스트 중\n",
        "print(mecab.morphs('밥 먹고 공부하려니 졸립고 나른하군 ㅠㅠ'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['밥', '먹', '고', '공부', '하', '려니', '졸립', '고', '나른', '하군', 'ㅠㅠ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpNyeTp3YOs5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30-BkfIzadXt"
      },
      "source": [
        "### 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD7BsB1EaaQb",
        "outputId": "f3c0cd10-0803-4c87-8b91-15c537ad64e5"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/naver_shopping.txt\", filename=\"ratings_total.txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ratings_total.txt', <http.client.HTTPMessage at 0x7f84bb597ed0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDvbKPNyafRb"
      },
      "source": [
        "total_data = pd.read_table('ratings_total.txt', names=['ratings', 'reviews'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2TpNowkas4T",
        "outputId": "f1168177-987d-4819-90aa-c0e949f7f455"
      },
      "source": [
        "print('전체 리뷰 갯수 :', len(total_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 리뷰 갯수 : 200000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "RBawGKkvawlz",
        "outputId": "0d6d58c4-929a-42ce-ebe2-3edd70cda1ce"
      },
      "source": [
        "total_data[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ratings</th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>배공빠르고 굿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ratings                                            reviews\n",
              "0        5                                            배공빠르고 굿\n",
              "1        2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고\n",
              "2        5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...\n",
              "3        2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...\n",
              "4        5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty__TGgYa7Yr"
      },
      "source": [
        "### 훈련 데이터와 테스트 데이터를 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "bk137xMca0Pj",
        "outputId": "3be03b2c-bb2d-49e8-ee7a-20e69e778ef4"
      },
      "source": [
        "total_data['label'] = np.select([total_data.ratings > 3], [1], default=0)\n",
        "total_data[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ratings</th>\n",
              "      <th>reviews</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>배공빠르고 굿</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ratings                                            reviews  label\n",
              "0        5                                            배공빠르고 굿      1\n",
              "1        2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고      0\n",
              "2        5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...      1\n",
              "3        2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...      0\n",
              "4        5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0OZWnDqbMab",
        "outputId": "b7ba9cee-8608-49c5-a94b-6d70a63780f0"
      },
      "source": [
        "# 각 열에 중복을 제외한 샘플의 수를 카운트\n",
        "total_data['ratings'].nunique(), total_data['reviews'].nunique(), total_data['label'].nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 199908, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HI347jFbdwN",
        "outputId": "c87d8f91-639b-4b34-bfff-1c90030c5373"
      },
      "source": [
        "total_data.drop_duplicates(subset=['reviews'], inplace=True) #reviews열에서 중복인 내용이 있다면 중복 제거\n",
        "print('총 샘플의 수 : ',len(total_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "총 샘플의 수 :  199908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCsI6t2cb3Jz",
        "outputId": "08389d05-d56f-480e-a4c1-bbc42cdf3e1e"
      },
      "source": [
        "# NULL값 유무\n",
        "print(total_data.isnull().values.any())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Tqmns3yb8fi",
        "outputId": "d4a104a4-b7c1-4df9-b050-f3a0c32b9078"
      },
      "source": [
        "# 훈련데이터와 테스트 데이터 3:1비율로 나눔\n",
        "train_data, test_data = train_test_split(total_data, test_size = 0.25, random_state=42)\n",
        "print('훈련용 리뷰의 갯수 : ', len(train_data))\n",
        "print('테스트용 리뷰의 갯수 : ', len(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련용 리뷰의 갯수 :  149931\n",
            "테스트용 리뷰의 갯수 :  49977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FatLEFpLcUlH"
      },
      "source": [
        "### 레이블의 분포 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "CsYd7kBQcP67",
        "outputId": "de4d16b9-4a64-4d38-8b43-85eb4714cd71"
      },
      "source": [
        "train_data['label'].value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f847aa98ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ceq9jS6cd5r",
        "outputId": "d44b8ac6-83ea-4a08-c0bf-0b2b3aa9b793"
      },
      "source": [
        "print(train_data.groupby('label').size().reset_index(name='count'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   label  count\n",
            "0      0  74918\n",
            "1      1  75013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XDdG0uscsej"
      },
      "source": [
        "### 데이터 정제하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGhp1O2Ncw7L"
      },
      "source": [
        "정규표현식을 사용하여 한글을 제외하고 모두 제거  \n",
        "빈 샘플이 생겼는지 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrgAkS8OcouT",
        "outputId": "ec8f32cb-a604-46cc-9596-89504ec86edf"
      },
      "source": [
        "train_data['reviews'] = train_data['reviews'].str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\"\")\n",
        "train_data['reviews'].replace('', np.nan, inplace=True)\n",
        "print(train_data.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ratings    0\n",
            "reviews    0\n",
            "label      0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4582: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl5e7LncdKs7",
        "outputId": "cb5dd834-dda1-4f5f-d7e2-b757377498af"
      },
      "source": [
        "test_data.drop_duplicates(subset=['reviews'], inplace=True)\n",
        "test_data['reviews'] = test_data['reviews'].str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\"\")\n",
        "test_data['reviews'].replace('', np.nan, inplace=True)\n",
        "test_data = test_data.dropna(how='any')\n",
        "print('전처리 후 테스트용 샘플의 갯수 : ',len(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전처리 후 테스트용 샘플의 갯수 :  49977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4582: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iScc-QZYd1Wq"
      },
      "source": [
        "### 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUWli8qnduXr",
        "outputId": "d97711c0-2287-4042-8c90-6016380b9f7c"
      },
      "source": [
        "mecab = Mecab()\n",
        "print(mecab.morphs('이런 상품도 상품이라고 허허허'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['이런', '상품', '도', '상품', '이', '라고', '허허허']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnD0JaVueQpK"
      },
      "source": [
        "### 불용어 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YGWmsbhd8f9"
      },
      "source": [
        "stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVv83qmkeKpi",
        "outputId": "46864eec-5318-4a2d-e182-31b392982a54"
      },
      "source": [
        "train_data['tokenized'] = train_data['reviews'].apply(mecab.morphs)\n",
        "train_data['tokenized'] = train_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1u5MFjDeiLy"
      },
      "source": [
        "test_data['tokenized'] = test_data['reviews'].apply(mecab.morphs)\n",
        "test_data['tokenized'] = test_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "999UZikUe19D"
      },
      "source": [
        "### 단어와 길이 분포 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aXUkWuLeuS6"
      },
      "source": [
        "negative_words = np.hstack(train_data[train_data.label == 0]['tokenized'].values)\n",
        "positive_words = np.hstack(train_data[train_data.label == 1]['tokenized'].values)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DST44L9MfwYa",
        "outputId": "45ed8c27-17dd-4463-f10b-3a89f0f3513f"
      },
      "source": [
        "## 부정리뷰에 대해서 빈도가 높은 상위 20개 단어 출력. Counter()를 사용하여 각 단어에 대한 빈도수 계산\n",
        "negative_word_count = Counter(negative_words)\n",
        "print(negative_word_count.most_common(20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('네요', 31799), ('는데', 20295), ('안', 19718), ('어요', 14849), ('있', 13200), ('너무', 13058), ('했', 11783), ('좋', 9812), ('배송', 9677), ('같', 8997), ('구매', 8876), ('어', 8869), ('거', 8854), ('없', 8670), ('아요', 8642), ('습니다', 8436), ('그냥', 8355), ('되', 8345), ('잘', 8029), ('않', 7984)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pLTwIy0gH-6",
        "outputId": "b2b5037a-0e25-4864-c7b0-7e1cdde06d08"
      },
      "source": [
        "positive_word_count = Counter(positive_words)\n",
        "print(positive_word_count.most_common(20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('좋', 39488), ('아요', 21184), ('네요', 19895), ('어요', 18686), ('잘', 18602), ('구매', 16171), ('습니다', 13320), ('있', 12391), ('배송', 12275), ('는데', 11670), ('했', 9818), ('합니다', 9801), ('먹', 9635), ('재', 9273), ('너무', 8397), ('같', 7868), ('만족', 7261), ('거', 6482), ('어', 6294), ('쓰', 6292)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "E_74Y-NngXgh",
        "outputId": "71d6a5b4-1d07-4214-948c-b054755ac79a"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "text_len = train_data[train_data['label']== 1]['tokenized'].map(lambda x: len(x))\n",
        "ax1.hist(text_len, color ='red')\n",
        "ax1.set_title('Positive Reviews')\n",
        "ax1.set_xlabel('length of samples')\n",
        "ax1.set_ylabel('number of samples')\n",
        "print('긍정 리뷰의 평균 길이 :',np.mean(text_len))\n",
        "\n",
        "text_len = train_data[train_data['label']==0]['tokenized'].map(lambda x: len(x))\n",
        "ax2.hist(text_len, color='blue')\n",
        "ax2.set_title('Negative Reviews')\n",
        "fig.suptitle('Words in texts')\n",
        "ax2.set_xlabel('length of samples')\n",
        "ax2.set_ylabel('number of samples')\n",
        "print('부정 리뷰의 평균 길이 :', np.mean(text_len))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "긍정 리뷰의 평균 길이 : 13.587751456414221\n",
            "부정 리뷰의 평균 길이 : 17.029512266744973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwI71OUehdFJ"
      },
      "source": [
        "x_train = train_data['tokenized'].values\n",
        "y_train = train_data['label'].values\n",
        "x_test = test_data['tokenized'].values\n",
        "y_test = test_data['label'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIByQ-P1ia1S"
      },
      "source": [
        "### 정수 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLCjsM6yiVSi"
      },
      "source": [
        "t = Tokenizer()\n",
        "t.fit_on_texts(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iopj-SoUiixh",
        "outputId": "4d9ab2d7-3358-4121-c624-31d8a25274fc"
      },
      "source": [
        "threshold = 2\n",
        "total_cnt = len(t.word_index) #단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍을 key와 value로 받는다.\n",
        "for key, value in t.word_counts.items():\n",
        "  total_freq = total_freq + value\n",
        "\n",
        "  if (value < threshold):\n",
        "    rare_cnt = rare_cnt + 1\n",
        "    rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀단어의 수: %s '% (threshold-1, rare_cnt))\n",
        "print('단어 집합에서 희귀 단어의 비율 :', (rare_cnt/ total_cnt)*100)\n",
        "print('전체 등장 빈도에서 희귀단어 등장 빈도 비율: ',(rare_freq/total_freq)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합(vocabulary)의 크기 : 39998\n",
            "등장 빈도가 1번 이하인 희귀단어의 수: 18213 \n",
            "단어 집합에서 희귀 단어의 비율 : 45.53477673883694\n",
            "전체 등장 빈도에서 희귀단어 등장 빈도 비율:  0.7935688376196857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4lHa5D0oq2p"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2mG0vwqjjR1",
        "outputId": "76d1a807-ef8d-45ee-cb71-77f1a1e05e0d"
      },
      "source": [
        "# 전체 단어 갯수 중 빈도수 2이하인 단어 갯수는 제거\n",
        "# 0번 패딩 토큰고 1번 OOV토큰을 고려해서 +2\n",
        "vocab_size = total_cnt - rare_cnt + 2\n",
        "print('단어 집합의 크기 :', vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 21787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqcFZSzlpXMK",
        "outputId": "f90dc611-23a4-4fb9-babf-a3c1bc35eaad"
      },
      "source": [
        "original_vocab_size = vocab_size + rare_cnt -2\n",
        "print('원래 vocab size : ', original_vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원래 vocab size :  39998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GXZhjgHpoXA"
      },
      "source": [
        "tokenizer = Tokenizer(vocab_size, oov_token='OOV')\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbSmtsX5p-Gv",
        "outputId": "eb921256-6fba-4d58-dbfc-94c11af30fcb"
      },
      "source": [
        "print(x_train[:3])\n",
        "print(x_test[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[67, 2060, 299, 14259, 263, 73, 6, 236, 168, 137, 805, 2951, 625, 2, 77, 62, 207, 40, 1343, 155, 3, 6], [482, 409, 52, 8530, 2561, 2517, 339, 2918, 250, 2357, 38, 473, 2], [46, 24, 825, 105, 35, 2372, 160, 7, 10, 8061, 4, 1319, 29, 140, 322, 41, 59, 160, 140, 7, 1916, 2, 113, 162, 1379, 323, 119, 136]]\n",
            "[[14, 704, 767, 116, 186, 252, 12], [339, 3904, 62, 3816, 1651], [11, 69, 2, 49, 164, 3, 27, 15, 6, 513, 289, 17, 92, 110, 564, 59, 7, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzauXhl-sBNg"
      },
      "source": [
        "### 패딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "Lcp-rVtOqGpv",
        "outputId": "235f873b-7979-4450-e6db-fb44dcabfce0"
      },
      "source": [
        "print('리뷰의 최대 길이 :', max(len(l) for l in x_train))\n",
        "print('리뷰의 평균 길이 :', sum(map(len, x_train))/len(x_train))\n",
        "plt.hist([len(s) for s in x_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "리뷰의 최대 길이 : 85\n",
            "리뷰의 평균 길이 : 15.307541469075774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAvlWL-usY6X"
      },
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "  cnt = 0\n",
        "  for s in nested_list:\n",
        "    if (len(s) <= max_len):\n",
        "      cnt = cnt + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율 : %s'%(max_len, (cnt/len(nested_list))*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LokiInCfsxYC",
        "outputId": "4844d1ae-b33a-4f41-b949-70d2e4d0bf73"
      },
      "source": [
        "max_len = 80\n",
        "below_threshold_len(max_len, x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플 중 길이가 80 이하인 샘플의 비율 : 99.99933302652553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUxlF3KJs8wH"
      },
      "source": [
        "x_train = pad_sequences(x_train, maxlen= max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7j4siyctMOe",
        "outputId": "2fde9ef0-73ba-4cb5-d73a-fcceac4b94f0"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(149931, 80)\n",
            "(49977, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vuhc-rw8tZwn"
      },
      "source": [
        "### GRU모델로 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wd2LqpqtQO4"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, GRU\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W3eVU8_tsvf"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100))\n",
        "model.add(GRU(128))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAaO4QIruDy2"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU6G8_WHuam_",
        "outputId": "ecf0d72e-d30e-4c8d-a85f-f538b42f5ea1"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(x_train, y_train, epochs= 30, callbacks=[es, mc], batch_size = 60, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2000/2000 [==============================] - 97s 45ms/step - loss: 0.2674 - acc: 0.8983 - val_loss: 0.2240 - val_acc: 0.9189\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.91893, saving model to best_model.h5\n",
            "Epoch 2/30\n",
            "2000/2000 [==============================] - 90s 45ms/step - loss: 0.1942 - acc: 0.9312 - val_loss: 0.2153 - val_acc: 0.9213\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.91893 to 0.92127, saving model to best_model.h5\n",
            "Epoch 3/30\n",
            "2000/2000 [==============================] - 89s 45ms/step - loss: 0.1609 - acc: 0.9434 - val_loss: 0.2310 - val_acc: 0.9166\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.92127\n",
            "Epoch 4/30\n",
            "2000/2000 [==============================] - 90s 45ms/step - loss: 0.1334 - acc: 0.9533 - val_loss: 0.2569 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.92127\n",
            "Epoch 5/30\n",
            "2000/2000 [==============================] - 90s 45ms/step - loss: 0.1108 - acc: 0.9611 - val_loss: 0.2630 - val_acc: 0.9129\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.92127\n",
            "Epoch 6/30\n",
            "2000/2000 [==============================] - 88s 44ms/step - loss: 0.0926 - acc: 0.9671 - val_loss: 0.3157 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.92127\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rD-XfzwLyLcd",
        "outputId": "a1543ab0-5ccd-4f2d-f0d3-b9d299fff192"
      },
      "source": [
        "loaded_model = load_model('best_model.h5')\n",
        "print('\\n 테스트 정확도 : %.4f'% (loaded_model.evaluate(x_test, y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 14s 9ms/step - loss: 0.2221 - acc: 0.9201\n",
            "\n",
            " 테스트 정확도 : 0.9201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_g-79myxFWH"
      },
      "source": [
        "### 리뷰 예측하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tkIJAeUuzon"
      },
      "source": [
        "def sentiment_predict(new_sentence):\n",
        "  new_sentence = mecab.morphs(new_sentence) #토큰화\n",
        "  new_sentence = [word for word in new_sentence if not word in stopwords] #불용어 제거\n",
        "  encoded = tokenizer.texts_to_sequences([new_sentence])\n",
        "  pad_new = pad_sequences(encoded, maxlen=max_len) # 패딩\n",
        "\n",
        "  score = float(loaded_model.predict(pad_new)) #d예측\n",
        "\n",
        "  if (score >0.5):\n",
        "    print('{:.2f}%확률로 긍정 리뷰입니다. '.format(score*100))\n",
        "  else:\n",
        "    print('{:.2f}%확률로 부정 리뷰입니다. '.format((1-score)*100))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXRt9uGZx5rE",
        "outputId": "8463c9f7-b312-4858-ff07-f48e93410077"
      },
      "source": [
        "sentiment_predict('이 상품 진짜 좋아요.. 저는 강추 대박')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "97.23%확률로 긍정 리뷰입니다. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZYcNk_Cx-Oe",
        "outputId": "71033ccc-cf6b-4607-c649-811acd045afa"
      },
      "source": [
        "sentiment_predict('이 상품 별로에요..')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.17%확률로 부정 리뷰입니다. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6ny9_5Wysmm",
        "outputId": "b6e3c9e3-e3e6-4e3b-9609-7a0ad5577fc4"
      },
      "source": [
        "sentiment_predict('진짜 배송 늦고 개별로 개짜증')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.36%확률로 부정 리뷰입니다. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1HfIYVryxiq",
        "outputId": "0d93b7d8-7ff5-4ee1-99c6-582ff6cdff36"
      },
      "source": [
        "sentiment_predict('그냥 그래요')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.32%확률로 부정 리뷰입니다. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE7dflXAyz7i",
        "outputId": "c2007532-de2a-4549-f329-66888f24d88f"
      },
      "source": [
        "sentiment_predict('ㄴㅇㄹㄴㅇㄹㄴㅇㄹㄴㅇㄹㅇㄴ귀찮아')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73.29%확률로 부정 리뷰입니다. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzB87MGZy5NJ",
        "outputId": "9bf7c0cd-3052-4349-cd27-eb48fafecabd"
      },
      "source": [
        "sentiment_predict('너무 짱이에요')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98.90%확률로 긍정 리뷰입니다. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC-OnuPL0uYG"
      },
      "source": [
        "## 글자 단위(Character-level)로 구현한 seq2seq 번역기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13AMKevyy7vj",
        "outputId": "c52a1077-cf01-4808-b92d-ed5c1da71511"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Mecab-ko-for-Google-Colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDBHPY-b2Mc_",
        "outputId": "bcd3d1e3-bb89-4d06-cce8-2f4e29925bc9"
      },
      "source": [
        "cd ../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jksEuOEh5HXV"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "dYSxZLjm2OTt",
        "outputId": "efb9a0dd-91e6-4ef1-aab5-932b897aa832"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/dataset/fra.txt'\n",
        "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
        "lines.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "      <th>cc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>161051</th>\n",
              "      <td>I am certain that you have noble thoughts.</td>\n",
              "      <td>Je suis sûr que vos pensées sont nobles.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5004</th>\n",
              "      <td>I'm 99% sure.</td>\n",
              "      <td>J'en suis sûr à 99%.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101864</th>\n",
              "      <td>Tom is in his sophomore year.</td>\n",
              "      <td>Tom est dans sa première année d'études supéri...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79211</th>\n",
              "      <td>The dog must stay outside!</td>\n",
              "      <td>Le chien doit rester dehors !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138340</th>\n",
              "      <td>You don't sound entirely convinced.</td>\n",
              "      <td>À vous entendre, vous n'êtes pas complètement ...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               eng  ...                                                 cc\n",
              "161051  I am certain that you have noble thoughts.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "5004                                 I'm 99% sure.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #6...\n",
              "101864               Tom is in his sophomore year.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #7...\n",
              "79211                   The dog must stay outside!  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #7...\n",
              "138340         You don't sound entirely convinced.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "eC1_dA_S5-4s",
        "outputId": "bd6b5f05-682b-4353-dce2-b7ee5be49108"
      },
      "source": [
        "lines = lines[['eng', 'fra']][:50000] #5만개 샘플사용\n",
        "lines.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37724</th>\n",
              "      <td>Tom was really busy.</td>\n",
              "      <td>Tom était très occupé.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26389</th>\n",
              "      <td>What is your plan?</td>\n",
              "      <td>Quel est votre plan ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48769</th>\n",
              "      <td>I'm not a drug addict.</td>\n",
              "      <td>Je ne suis pas une droguée.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15947</th>\n",
              "      <td>Watch your back.</td>\n",
              "      <td>Surveille tes arrières !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20412</th>\n",
              "      <td>Tom looked happy.</td>\n",
              "      <td>Tom avait l'air heureux.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          eng                          fra\n",
              "37724    Tom was really busy.       Tom était très occupé.\n",
              "26389      What is your plan?        Quel est votre plan ?\n",
              "48769  I'm not a drug addict.  Je ne suis pas une droguée.\n",
              "15947        Watch your back.     Surveille tes arrières !\n",
              "20412       Tom looked happy.     Tom avait l'air heureux."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "nn3MQA0e6XOB",
        "outputId": "fd2b39f0-1375-4ab7-ce56-d926ca14814c"
      },
      "source": [
        "# 시작토큰과 종료 토큰 추가\n",
        "sos_token = '\\t'\n",
        "eos_token = '\\n'\n",
        "lines.fra = lines.fra.apply(lambda x: '\\t' + x + '\\n')\n",
        "print('전체 샘플의 수 :',len(lines))\n",
        "lines.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플의 수 : 50000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31929</th>\n",
              "      <td>We're all students.</td>\n",
              "      <td>\\tNous sommes tous étudiants.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19879</th>\n",
              "      <td>These are my CDs.</td>\n",
              "      <td>\\tCe sont mes CDs.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19406</th>\n",
              "      <td>Please follow me.</td>\n",
              "      <td>\\tVeuillez me suivre.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4666</th>\n",
              "      <td>I can fix it.</td>\n",
              "      <td>\\tJe peux le réparer.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34756</th>\n",
              "      <td>I know Tom is tough.</td>\n",
              "      <td>\\tJe sais que Tom est difficile.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        eng                                 fra\n",
              "31929   We're all students.     \\tNous sommes tous étudiants.\\n\n",
              "19879     These are my CDs.                \\tCe sont mes CDs.\\n\n",
              "19406     Please follow me.             \\tVeuillez me suivre.\\n\n",
              "4666          I can fix it.             \\tJe peux le réparer.\\n\n",
              "34756  I know Tom is tough.  \\tJe sais que Tom est difficile.\\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uXSOPBL6yw0",
        "outputId": "3b443269-aa61-43b1-ed08-0c214375e70f"
      },
      "source": [
        "eng_tokenizer = Tokenizer(char_level=True)\n",
        "# 글자 단위로 토큰화\n",
        "eng_tokenizer.fit_on_texts(lines.eng)\n",
        "# 50000개의 행을 가진 eng의 각 행에 토큰화 수행\n",
        "input_text = eng_tokenizer.texts_to_sequences(lines.eng)\n",
        "# 단어를 숫자값 인덱스로 변환하여 저장\n",
        "input_text[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[19, 3, 8], [19, 3, 8], [19, 3, 8]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_HnAHfd7VKM",
        "outputId": "146b7514-5406-4823-fbf7-d80c4bd97f26"
      },
      "source": [
        "fra_tokenizer = Tokenizer(char_level=True)\n",
        "# 글자 단위로 토큰화\n",
        "fra_tokenizer.fit_on_texts(lines.fra)\n",
        "# 50000개의 행을 가진 eng의 각 행에 토큰화 수행\n",
        "target_text = fra_tokenizer.texts_to_sequences(lines.fra)\n",
        "# 단어를 숫자값 인덱스로 변환하여 저장\n",
        "target_text[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[10, 19, 5, 1, 31, 11],\n",
              " [10, 15, 5, 12, 16, 29, 2, 14, 11],\n",
              " [10, 26, 9, 8, 28, 2, 1, 31, 11]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLj52slO7jef",
        "outputId": "d35e8267-0595-4c0a-96b0-71bd726c882e"
      },
      "source": [
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
        "print('영어 단어장의 크기 :',eng_vocab_size)\n",
        "print('프랑스어 단어장의 크기 :', fra_vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 단어장의 크기 : 52\n",
            "프랑스어 단어장의 크기 : 73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMaES32G74Kk",
        "outputId": "8747ff9e-7b7a-4991-cc90-0582dcfb6444"
      },
      "source": [
        "max_eng_seq_len = max([len(line) for line in input_text])\n",
        "max_fra_seq_len = max([len(line) for line in target_text])\n",
        "\n",
        "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
        "print('프랑스 시퀀스의 최대 길이', max_fra_seq_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 시퀀스의 최대 길이 22\n",
            "프랑스 시퀀스의 최대 길이 74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84agcYGw8T1s",
        "outputId": "3c329b3f-68c7-42e4-8553-4529284993e9"
      },
      "source": [
        "print('전체 샘플의 수 :', len(lines))\n",
        "print('영어 단어장의 크기:', eng_vocab_size)\n",
        "print('프랑스어 단어장의 크기:', fra_vocab_size)\n",
        "print('영어 시퀀스의 최대 길이:', max_eng_seq_len)\n",
        "print('프랑스 시퀀스의 최대 길이', max_fra_seq_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플의 수 : 50000\n",
            "영어 단어장의 크기: 52\n",
            "프랑스어 단어장의 크기: 73\n",
            "영어 시퀀스의 최대 길이: 22\n",
            "프랑스 시퀀스의 최대 길이 74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJQ35mum8oS7"
      },
      "source": [
        "encoder_input = input_text\n",
        "\n",
        "# 종료 토큰 제거\n",
        "decoder_input = [[char for char in line if char != fra_tokenizer.word_index[eos_token]] for line in target_text]\n",
        "# 시작 토큰 제거\n",
        "decoder_target = [[char for char in line if char != fra_tokenizer.word_index[sos_token]] for line in target_text]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-V7HU9W9Sij",
        "outputId": "8c1be4b3-8bd9-4d9f-9687-561cddc97699"
      },
      "source": [
        "print(decoder_input[:3]) # <eos>토큰 제거\n",
        "print(decoder_target[:3]) # <sos>토큰 제거"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10, 19, 5, 1, 31], [10, 15, 5, 12, 16, 29, 2, 14], [10, 26, 9, 8, 28, 2, 1, 31]]\n",
            "[[19, 5, 1, 31, 11], [15, 5, 12, 16, 29, 2, 14, 11], [26, 9, 8, 28, 2, 1, 31, 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ4bavoY9cOE",
        "outputId": "2c84c2af-1a14-4081-d7a1-e307dddb40b4"
      },
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen=max_eng_seq_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_fra_seq_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_fra_seq_len, padding='post')\n",
        "\n",
        "print('영어 데이터의 크기(shape) :', np.shape(encoder_input))\n",
        "print('프랑스어 입력데이터의 크기 : ', np.shape(decoder_input))\n",
        "print('프랑스어 출력데이터의 크기 : ', np.shape(decoder_target))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 데이터의 크기(shape) : (50000, 22)\n",
            "프랑스어 입력데이터의 크기 :  (50000, 74)\n",
            "프랑스어 출력데이터의 크기 :  (50000, 74)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCev-GzP-NZ8",
        "outputId": "3678f881-4379-4c24-9508-15368f3fd0ce"
      },
      "source": [
        "print(encoder_input[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19  3  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfeYrz3p-VQT",
        "outputId": "c62f9237-eba9-4a25-df7c-0054560a162a"
      },
      "source": [
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)\n",
        "\n",
        "print('영어 데이터의 크기 :', np.shape(encoder_input))\n",
        "print('프랑스어 입력데이터의 크기 : ', np.shape(decoder_input))\n",
        "print('프랑스어 출력데이터의 크기 :', np.shape(decoder_target)) #샘플의 수 x 샘플의 길이 x 단어장의 크기"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 데이터의 크기 : (50000, 22, 52)\n",
            "프랑스어 입력데이터의 크기 :  (50000, 74, 73)\n",
            "프랑스어 출력데이터의 크기 : (50000, 74, 73)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hccnG-q-1Mz",
        "outputId": "73c88d95-edc7-444c-d11e-516a538329fb"
      },
      "source": [
        "n_of_val = 3000\n",
        "\n",
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]\n",
        "\n",
        "print('영어 학습데이터의 크기 :', np.shape(encoder_input))\n",
        "print('프랑스어 학습 입력데이터의 크기 :', np.shape(decoder_input))\n",
        "print('프랑스어 학습 출력데이터의 크기 :',np.shape(decoder_target))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 학습데이터의 크기 : (50000, 22, 52)\n",
            "프랑스어 학습 입력데이터의 크기 : (50000, 74, 73)\n",
            "프랑스어 학습 출력데이터의 크기 : (50000, 74, 73)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpu8EDCD_3Hb"
      },
      "source": [
        "### 모델 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHrMd6dt_w0D"
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmxsGZWIACZL"
      },
      "source": [
        "# LSTM셀의 마지막 time step의 hidden state와 cell state를 디코더 LSTM의 첫번째 hidden state와 cell state전달해주자\n",
        "\n",
        "encoder_inputs = Input(shape=(None, eng_vocab_size))\n",
        "# 입력 텐서를 생성\n",
        "encoder_lstm = LSTM(units= 256, return_state=True)\n",
        "# hidden state 256인 LSTM을 생성\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "# 디코더로 전달할 hidden state, cell state를 리턴. encoder_output은 여기서는 불필요.\n",
        "encoder_states = [state_h, state_c]\n",
        "# hidden state와 cell state를 다음 time step으로 전달하기 위해서 별도로 저장"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJuMfk6CAvtT"
      },
      "source": [
        "decoder_inputs = Input(shape=(None, fra_vocab_size))\n",
        "# 입력 텐서 생성\n",
        "decoder_lstm = LSTM(units=256, return_sequences= True, return_state=True)\n",
        "# hidden state size 256 디코더 LSTM 생성\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state = encoder_states)\n",
        "# decoder output는 모든 timestep의 hidden state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tox2i7CEB4RL"
      },
      "source": [
        "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONPwkG6wCD_y",
        "outputId": "62f2a792-5225-4655-9a66-479cfb93ec14"
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 52)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 73)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 256), (None, 316416      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 256),  337920      input_2[0][0]                    \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 73)     18761       lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 673,097\n",
            "Trainable params: 673,097\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol2INN2cCkWS",
        "outputId": "3682602e-bff2-4db5-9521-dd243032d7d5"
      },
      "source": [
        "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), batch_size=128, epochs=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "368/368 [==============================] - 21s 48ms/step - loss: 0.9067 - val_loss: 0.8044\n",
            "Epoch 2/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.5548 - val_loss: 0.6469\n",
            "Epoch 3/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.4581 - val_loss: 0.5617\n",
            "Epoch 4/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.4079 - val_loss: 0.5151\n",
            "Epoch 5/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.3702 - val_loss: 0.4760\n",
            "Epoch 6/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.3433 - val_loss: 0.4518\n",
            "Epoch 7/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.3226 - val_loss: 0.4258\n",
            "Epoch 8/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.3060 - val_loss: 0.4151\n",
            "Epoch 9/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.2922 - val_loss: 0.4025\n",
            "Epoch 10/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.2807 - val_loss: 0.3926\n",
            "Epoch 11/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.2708 - val_loss: 0.3807\n",
            "Epoch 12/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.2619 - val_loss: 0.3795\n",
            "Epoch 13/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.2541 - val_loss: 0.3730\n",
            "Epoch 14/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.2471 - val_loss: 0.3696\n",
            "Epoch 15/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.2407 - val_loss: 0.3670\n",
            "Epoch 16/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.2348 - val_loss: 0.3706\n",
            "Epoch 17/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.2292 - val_loss: 0.3659\n",
            "Epoch 18/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.2243 - val_loss: 0.3654\n",
            "Epoch 19/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.2195 - val_loss: 0.3615\n",
            "Epoch 20/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.2150 - val_loss: 0.3599\n",
            "Epoch 21/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.2108 - val_loss: 0.3590\n",
            "Epoch 22/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.2068 - val_loss: 0.3585\n",
            "Epoch 23/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.2030 - val_loss: 0.3578\n",
            "Epoch 24/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.1994 - val_loss: 0.3613\n",
            "Epoch 25/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.1959 - val_loss: 0.3607\n",
            "Epoch 26/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.1927 - val_loss: 0.3618\n",
            "Epoch 27/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.1896 - val_loss: 0.3659\n",
            "Epoch 28/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.1865 - val_loss: 0.3618\n",
            "Epoch 29/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.1835 - val_loss: 0.3635\n",
            "Epoch 30/30\n",
            "368/368 [==============================] - 17s 46ms/step - loss: 0.1808 - val_loss: 0.3678\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f83f4585410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBNqjsEIF7o_"
      },
      "source": [
        "### 모델 테스트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz27PQJQF_Er"
      },
      "source": [
        "훈련시에 학습해야할 타겟문장을 디코더 모델의 입력, 출력 시퀀스로 넣어주고, 디코더 모델이 타겟문장을 한꺼번에 출력하게 할 수 있습니다. 테스트 단계는 불가능!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEkPL-4cGLJy"
      },
      "source": [
        "테스트 단계에서 디코더 동작 순서\n",
        "- 인코더에 입력 문장을 넣어 마지막 time step의 hidden, cell state를 얻는다.\n",
        "- 토큰인 \\t를 디코더에 입력한다.\n",
        "- 이전 timestep의 출력층의 예측결과를 현재 timestep의 입력으로 한다.\n",
        "- 3을 반복하다가 토큰인 \\n가 예측되면 이를 중단한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJkZawdfDJNC",
        "outputId": "be9f0eed-742e-49fc-e5f1-39737c9c17bf"
      },
      "source": [
        "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)\n",
        "encoder_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None, 52)]        0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  [(None, 256), (None, 256) 316416    \n",
            "=================================================================\n",
            "Total params: 316,416\n",
            "Trainable params: 316,416\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ympxi5GoGtJK"
      },
      "source": [
        "decoder_state_input_h = Input(shape=(256,))\n",
        "# 이전 timestep의 hidden state를 저장하는 텐서\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "# 이전 timestep의 cell state를 저장하는 텐서\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "# 이전 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
        "\n",
        "# decoder_state_inputs를 현재 time step의 초기상태로 사용\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
        "# 현재 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
        "decoder_states = [state_h, state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WT-r1ulHIpB",
        "outputId": "b4228cf9-4b4e-4f93-f2b5-e925df8acbf8"
      },
      "source": [
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model= Model(inputs=[decoder_inputs] + decoder_state_inputs, outputs=[decoder_outputs]+decoder_states)\n",
        "decoder_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None, 73)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 256),  337920      input_2[0][0]                    \n",
            "                                                                 input_7[0][0]                    \n",
            "                                                                 input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 73)     18761       lstm_1[2][0]                     \n",
            "==================================================================================================\n",
            "Total params: 356,681\n",
            "Trainable params: 356,681\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6HA3rR-H0Oq"
      },
      "source": [
        "eng2idx = eng_tokenizer.word_index\n",
        "fra2idx = fra_tokenizer.word_index\n",
        "idx2eng = eng_tokenizer.index_word\n",
        "idx2fra = fra_tokenizer.index_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILx_q7h8IEWa"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # 입력으로부터 인코더의 상태를 얻음\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "  target_seq = np.zeros((1, 1, fra_vocab_size))\n",
        "  target_seq[0, 0, fra2idx['\\t']] =1\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = \"\"\n",
        "\n",
        "  # stop condition이 True가 될떄까지 루프 반복\n",
        "  while not stop_condition:\n",
        "    # 이전 시점의 상태 state_value를 현 시점의 초기 상태로 사용\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq]+ states_value)\n",
        "\n",
        "    # 예측 결과를 문자로 변환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = idx2fra[sampled_token_index]\n",
        "\n",
        "    # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "    decoded_sentence += sampled_char\n",
        "\n",
        "    # <eos>에 도달하거나 최대 길이를 넘으면 중단\n",
        "    if (sampled_char == '\\n' or\n",
        "        len(decoded_sentence) > max_fra_seq_len):\n",
        "      stop_condition = True\n",
        "\n",
        "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "    target_seq = np.zeros((1, 1, fra_vocab_size))\n",
        "    target_seq[0, 0, sampled_token_index] =1\n",
        "\n",
        "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "    states_value = [h, c]\n",
        "  return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTgzwt5jJEZS",
        "outputId": "8c53855b-ad56-49b6-e719-cc8d966a9318"
      },
      "source": [
        "import numpy as np\n",
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  # 입력 문장의 인덱스 (자유롭게 바꿔서 테스트 해보세요!)\n",
        "  input_seq = encoder_input[seq_index: seq_index +1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print(35 * \"-\")\n",
        "  print('입력 문장 :', lines.eng[seq_index])\n",
        "  print('정답 문장 :', lines.fra[seq_index][1:len(lines.fra[seq_index])-1])\n",
        "  # '\\t'와 '\\n'을 빼고 출력\n",
        "  print('번역기가 번역한 문장 :', decoded_sentence[:len(decoded_sentence)-1])\n",
        "  # '\\n'을 빼고 출력"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------\n",
            "입력 문장 : Hi.\n",
            "정답 문장 : Salut !\n",
            "번역기가 번역한 문장 : salut.\n",
            "-----------------------------------\n",
            "입력 문장 : I won!\n",
            "정답 문장 : Je l'ai emporté !\n",
            "번역기가 번역한 문장 : je suis de l'expérience !\n",
            "-----------------------------------\n",
            "입력 문장 : I fled.\n",
            "정답 문장 : J'ai fui.\n",
            "번역기가 번역한 문장 : je suis parti.\n",
            "-----------------------------------\n",
            "입력 문장 : Hug Tom.\n",
            "정답 문장 : Fais un câlin à Tom.\n",
            "번역기가 번역한 문장 : servez-vous.\n",
            "-----------------------------------\n",
            "입력 문장 : I give in.\n",
            "정답 문장 : Je donne ma langue au chat.\n",
            "번역기가 번역한 문장 : je suis devenue.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DsHpXWOJjc5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}