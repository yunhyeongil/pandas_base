{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2일차_실습하기_윤형일.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yunhyeongil/pandas_base/blob/main/2%EC%9D%BC%EC%B0%A8_%EC%8B%A4%EC%8A%B5%ED%95%98%EA%B8%B0_%EC%9C%A4%ED%98%95%EC%9D%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdDtqXEPZIHv"
      },
      "source": [
        "import re, collections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3_ISbvdcd9I"
      },
      "source": [
        "num_merges = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Hz1RIy8co8u"
      },
      "source": [
        "dictionary = {'l o w </w>' : 5,\n",
        "         'l o w e r </w>' : 2,\n",
        "         'n e w e s t </w>':6,\n",
        "         'w i d e s t </w>':3\n",
        "         }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwKUrfELc_rm"
      },
      "source": [
        "def get_stats(dictionary):\n",
        "  # 유니그램의 pair들의 빈도수를 카운트\n",
        "  \n",
        "  pairs = collections.defaultdict(int)    # default dictionary type initialize\n",
        "  print(type(pairs))\n",
        "  for word, freq in dictionary.items(): # 딕셔너리 아이템의 키와 단어의 카운트 수를 읽어온다.\n",
        "    symbols = word.split() # word: 'l o w </w>'  , symbols : ['l', 'o', 'w', '</w>']\n",
        "    print(\"type->\", symbols)\n",
        "    for i in range(len(symbols)-1): # 심볼안 리스트 각 char가 pairs dictionary에 저장\n",
        "      pairs[symbols[i], symbols[i+1]] += freq # pairs의 첫번째 key는 ('l','o') value 는 5\n",
        "  print('현재 pair들의 빈도수 :', dict(pairs)) # dictionary를 완성한후 전체 빈도수 출력\n",
        "  return pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lwtnREweS4I"
      },
      "source": [
        "def merge_dictionary(pair, v_in): # 첫번째 loop 인 경우 ('e','s') parameter  v_in -> 기존 dictionary\n",
        "    v_out = {}\n",
        "    bigram = re.escape(' '.join(pair)) \n",
        "    print(\"bigram->#\"+bigram+\"#\") #  -->e\\' 's\n",
        "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')  #'(?<!\\\\S)e\\\\ s(?!\\\\S)' # 부정형후방탐색 앞에 일반문자가 아닌 스페이스가 나타난다.  \n",
        "    print(\"p->\",p)\n",
        "    for word in v_in:\n",
        "        print(\"word ->\"+ word)\n",
        "        w_out = p.sub(''.join(pair), word) # es dictionary에 있는 단어중 'n e w e s t </w>'  es' 가 포함된 단어를 찾아 대체\n",
        "        print(\"w_out\",w_out)\n",
        "        v_out[w_out] = v_in[word]\n",
        "    return v_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oLhaJdNevbO"
      },
      "source": [
        "bpe_codes = {}\n",
        "bpe_codes_reverse = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srNL_KWUe1G9",
        "outputId": "60fbc5dd-8b0c-4654-ea5d-15b2c6eddf98"
      },
      "source": [
        "for i in range(num_merges):\n",
        "  print(\">> Step {0}\".format(i+1))\n",
        "  pairs = get_stats(dictionary)\n",
        "  best = max(pairs, key=pairs.get) # 1st loop : pairs dictionary 값중 가장 빈도수가 많은 dictionary의 key 인 ('e','s')를 가져옴 type tuple\n",
        "  print(\"best type\", type(best))\n",
        "  print(\"best value\",best )\n",
        "  dictionary = merge_dictionary(best, dictionary)\n",
        "\n",
        "  bpe_codes[best] = i  # bpe code에 index를 넣는다.\n",
        "  bpe_codes_reverse[best[0] + best[1]] = best\n",
        "\n",
        "  print(\"new merge: {}\".format(best))\n",
        "  print(\"dictionary: {}\".format(dictionary))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">> Step 1\n",
            "<class 'collections.defaultdict'>\n",
            "type-> ['l', 'o', 'w', '</w>']\n",
            "type-> ['l', 'o', 'w', 'e', 'r', '</w>']\n",
            "type-> ['n', 'e', 'w', 'e', 's', 't', '</w>']\n",
            "type-> ['w', 'i', 'd', 'e', 's', 't', '</w>']\n",
            "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 8, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('e', 's'): 9, ('s', 't'): 9, ('t', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'e'): 3}\n",
            "best type <class 'tuple'>\n",
            "best value ('e', 's')\n",
            "bigram->#e\\ s#\n",
            "p-> re.compile('(?<!\\\\S)e\\\\ s(?!\\\\S)')\n",
            "word ->l o w </w>\n",
            "w_out l o w </w>\n",
            "word ->l o w e r </w>\n",
            "w_out l o w e r </w>\n",
            "word ->n e w e s t </w>\n",
            "w_out n e w es t </w>\n",
            "word ->w i d e s t </w>\n",
            "w_out w i d es t </w>\n",
            "new merge: ('e', 's')\n",
            "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w es t </w>': 6, 'w i d es t </w>': 3}\n",
            ">> Step 2\n",
            "<class 'collections.defaultdict'>\n",
            "type-> ['l', 'o', 'w', '</w>']\n",
            "type-> ['l', 'o', 'w', 'e', 'r', '</w>']\n",
            "type-> ['n', 'e', 'w', 'es', 't', '</w>']\n",
            "type-> ['w', 'i', 'd', 'es', 't', '</w>']\n",
            "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'es'): 6, ('es', 't'): 9, ('t', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'es'): 3}\n",
            "best type <class 'tuple'>\n",
            "best value ('es', 't')\n",
            "bigram->#es\\ t#\n",
            "p-> re.compile('(?<!\\\\S)es\\\\ t(?!\\\\S)')\n",
            "word ->l o w </w>\n",
            "w_out l o w </w>\n",
            "word ->l o w e r </w>\n",
            "w_out l o w e r </w>\n",
            "word ->n e w es t </w>\n",
            "w_out n e w est </w>\n",
            "word ->w i d es t </w>\n",
            "w_out w i d est </w>\n",
            "new merge: ('es', 't')\n",
            "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est </w>': 6, 'w i d est </w>': 3}\n",
            ">> Step 3\n",
            "<class 'collections.defaultdict'>\n",
            "type-> ['l', 'o', 'w', '</w>']\n",
            "type-> ['l', 'o', 'w', 'e', 'r', '</w>']\n",
            "type-> ['n', 'e', 'w', 'est', '</w>']\n",
            "type-> ['w', 'i', 'd', 'est', '</w>']\n",
            "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est'): 6, ('est', '</w>'): 9, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est'): 3}\n",
            "best type <class 'tuple'>\n",
            "best value ('est', '</w>')\n",
            "bigram->#est\\ </w>#\n",
            "p-> re.compile('(?<!\\\\S)est\\\\ </w>(?!\\\\S)')\n",
            "word ->l o w </w>\n",
            "w_out l o w </w>\n",
            "word ->l o w e r </w>\n",
            "w_out l o w e r </w>\n",
            "word ->n e w est </w>\n",
            "w_out n e w est</w>\n",
            "word ->w i d est </w>\n",
            "w_out w i d est</w>\n",
            "new merge: ('est', '</w>')\n",
            "dictionary: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n",
            ">> Step 4\n",
            "<class 'collections.defaultdict'>\n",
            "type-> ['l', 'o', 'w', '</w>']\n",
            "type-> ['l', 'o', 'w', 'e', 'r', '</w>']\n",
            "type-> ['n', 'e', 'w', 'est</w>']\n",
            "type-> ['w', 'i', 'd', 'est</w>']\n",
            "현재 pair들의 빈도수 : {('l', 'o'): 7, ('o', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "best type <class 'tuple'>\n",
            "best value ('l', 'o')\n",
            "bigram->#l\\ o#\n",
            "p-> re.compile('(?<!\\\\S)l\\\\ o(?!\\\\S)')\n",
            "word ->l o w </w>\n",
            "w_out lo w </w>\n",
            "word ->l o w e r </w>\n",
            "w_out lo w e r </w>\n",
            "word ->n e w est</w>\n",
            "w_out n e w est</w>\n",
            "word ->w i d est</w>\n",
            "w_out w i d est</w>\n",
            "new merge: ('l', 'o')\n",
            "dictionary: {'lo w </w>': 5, 'lo w e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n",
            ">> Step 5\n",
            "<class 'collections.defaultdict'>\n",
            "type-> ['lo', 'w', '</w>']\n",
            "type-> ['lo', 'w', 'e', 'r', '</w>']\n",
            "type-> ['n', 'e', 'w', 'est</w>']\n",
            "type-> ['w', 'i', 'd', 'est</w>']\n",
            "현재 pair들의 빈도수 : {('lo', 'w'): 7, ('w', '</w>'): 5, ('w', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "best type <class 'tuple'>\n",
            "best value ('lo', 'w')\n",
            "bigram->#lo\\ w#\n",
            "p-> re.compile('(?<!\\\\S)lo\\\\ w(?!\\\\S)')\n",
            "word ->lo w </w>\n",
            "w_out low </w>\n",
            "word ->lo w e r </w>\n",
            "w_out low e r </w>\n",
            "word ->n e w est</w>\n",
            "w_out n e w est</w>\n",
            "word ->w i d est</w>\n",
            "w_out w i d est</w>\n",
            "new merge: ('lo', 'w')\n",
            "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n",
            ">> Step 6\n",
            "<class 'collections.defaultdict'>\n",
            "type-> ['low', '</w>']\n",
            "type-> ['low', 'e', 'r', '</w>']\n",
            "type-> ['n', 'e', 'w', 'est</w>']\n",
            "type-> ['w', 'i', 'd', 'est</w>']\n",
            "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('n', 'e'): 6, ('e', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "best type <class 'tuple'>\n",
            "best value ('n', 'e')\n",
            "bigram->#n\\ e#\n",
            "p-> re.compile('(?<!\\\\S)n\\\\ e(?!\\\\S)')\n",
            "word ->low </w>\n",
            "w_out low </w>\n",
            "word ->low e r </w>\n",
            "w_out low e r </w>\n",
            "word ->n e w est</w>\n",
            "w_out ne w est</w>\n",
            "word ->w i d est</w>\n",
            "w_out w i d est</w>\n",
            "new merge: ('n', 'e')\n",
            "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'ne w est</w>': 6, 'w i d est</w>': 3}\n",
            ">> Step 7\n",
            "<class 'collections.defaultdict'>\n",
            "type-> ['low', '</w>']\n",
            "type-> ['low', 'e', 'r', '</w>']\n",
            "type-> ['ne', 'w', 'est</w>']\n",
            "type-> ['w', 'i', 'd', 'est</w>']\n",
            "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('ne', 'w'): 6, ('w', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "best type <class 'tuple'>\n",
            "best value ('ne', 'w')\n",
            "bigram->#ne\\ w#\n",
            "p-> re.compile('(?<!\\\\S)ne\\\\ w(?!\\\\S)')\n",
            "word ->low </w>\n",
            "w_out low </w>\n",
            "word ->low e r </w>\n",
            "w_out low e r </w>\n",
            "word ->ne w est</w>\n",
            "w_out new est</w>\n",
            "word ->w i d est</w>\n",
            "w_out w i d est</w>\n",
            "new merge: ('ne', 'w')\n",
            "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'new est</w>': 6, 'w i d est</w>': 3}\n",
            ">> Step 8\n",
            "<class 'collections.defaultdict'>\n",
            "type-> ['low', '</w>']\n",
            "type-> ['low', 'e', 'r', '</w>']\n",
            "type-> ['new', 'est</w>']\n",
            "type-> ['w', 'i', 'd', 'est</w>']\n",
            "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('new', 'est</w>'): 6, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "best type <class 'tuple'>\n",
            "best value ('new', 'est</w>')\n",
            "bigram->#new\\ est</w>#\n",
            "p-> re.compile('(?<!\\\\S)new\\\\ est</w>(?!\\\\S)')\n",
            "word ->low </w>\n",
            "w_out low </w>\n",
            "word ->low e r </w>\n",
            "w_out low e r </w>\n",
            "word ->new est</w>\n",
            "w_out newest</w>\n",
            "word ->w i d est</w>\n",
            "w_out w i d est</w>\n",
            "new merge: ('new', 'est</w>')\n",
            "dictionary: {'low </w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'w i d est</w>': 3}\n",
            ">> Step 9\n",
            "<class 'collections.defaultdict'>\n",
            "type-> ['low', '</w>']\n",
            "type-> ['low', 'e', 'r', '</w>']\n",
            "type-> ['newest</w>']\n",
            "type-> ['w', 'i', 'd', 'est</w>']\n",
            "현재 pair들의 빈도수 : {('low', '</w>'): 5, ('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "best type <class 'tuple'>\n",
            "best value ('low', '</w>')\n",
            "bigram->#low\\ </w>#\n",
            "p-> re.compile('(?<!\\\\S)low\\\\ </w>(?!\\\\S)')\n",
            "word ->low </w>\n",
            "w_out low</w>\n",
            "word ->low e r </w>\n",
            "w_out low e r </w>\n",
            "word ->newest</w>\n",
            "w_out newest</w>\n",
            "word ->w i d est</w>\n",
            "w_out w i d est</w>\n",
            "new merge: ('low', '</w>')\n",
            "dictionary: {'low</w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'w i d est</w>': 3}\n",
            ">> Step 10\n",
            "<class 'collections.defaultdict'>\n",
            "type-> ['low</w>']\n",
            "type-> ['low', 'e', 'r', '</w>']\n",
            "type-> ['newest</w>']\n",
            "type-> ['w', 'i', 'd', 'est</w>']\n",
            "현재 pair들의 빈도수 : {('low', 'e'): 2, ('e', 'r'): 2, ('r', '</w>'): 2, ('w', 'i'): 3, ('i', 'd'): 3, ('d', 'est</w>'): 3}\n",
            "best type <class 'tuple'>\n",
            "best value ('w', 'i')\n",
            "bigram->#w\\ i#\n",
            "p-> re.compile('(?<!\\\\S)w\\\\ i(?!\\\\S)')\n",
            "word ->low</w>\n",
            "w_out low</w>\n",
            "word ->low e r </w>\n",
            "w_out low e r </w>\n",
            "word ->newest</w>\n",
            "w_out newest</w>\n",
            "word ->w i d est</w>\n",
            "w_out wi d est</w>\n",
            "new merge: ('w', 'i')\n",
            "dictionary: {'low</w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'wi d est</w>': 3}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPU6cCdkfclG",
        "outputId": "bd0e2a32-0afc-4358-c804-2ee28ab63ca5"
      },
      "source": [
        "print(bpe_codes)\n",
        "# bpe_code를 출력하면 merge 했던 기록이 출력"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{('e', 's'): 0, ('es', 't'): 1, ('est', '</w>'): 2, ('l', 'o'): 3, ('lo', 'w'): 4, ('n', 'e'): 5, ('ne', 'w'): 6, ('new', 'est</w>'): 7, ('low', '</w>'): 8, ('w', 'i'): 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjMnkNuulF-0"
      },
      "source": [
        "## OOV에 대처하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S_5LYvUlJPT"
      },
      "source": [
        "def get_pairs(word):\n",
        "    \"\"\"Return set of symbol pairs in a word.\n",
        "    Word is represented as a tuple of symbols (symbols being variable-length strings).\n",
        "    \"\"\"\n",
        "    pairs = set()\n",
        "    prev_char = word[0]\n",
        "    for char in word[1:]:\n",
        "        pairs.add((prev_char, char))\n",
        "        prev_char = char\n",
        "    return pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfb5PV0FlVcF"
      },
      "source": [
        "def encode(orig):\n",
        "    \"\"\"Encode word based on list of BPE merge operations, which are applied consecutively\"\"\"\n",
        "\n",
        "    word = tuple(orig) + ('</w>',) #문자열을 튜플로 변환\n",
        "    #display(Markdown(\"__word split into characters:__ <tt>{}</tt>\".format(word)))\n",
        "    print(\"__word split into characters:__ <tt>{}</tt>\".format(word))\n",
        "\n",
        "    pairs = get_pairs(word)    \n",
        "\n",
        "    if not pairs:\n",
        "        return orig\n",
        "\n",
        "    iteration = 0\n",
        "    while True:\n",
        "        iteration += 1\n",
        "        #display(Markdown(\"__Iteration {}:__\".format(iteration)))\n",
        "        print(\"__Iteration {}:__\".format(iteration))\n",
        "\n",
        "        print(\"bigrams in the word: {}\".format(pairs))\n",
        "        bigram = min(pairs, key = lambda pair: bpe_codes.get(pair, float('inf')))\n",
        "        print(\"candidate for merging: {}\".format(bigram))\n",
        "        if bigram not in bpe_codes:\n",
        "            #display(Markdown(\"__Candidate not in BPE merges, algorithm stops.__\"))\n",
        "            print(\"__Candidate not in BPE merges, algorithm stops.__\")\n",
        "            break\n",
        "        first, second = bigram\n",
        "        new_word = []\n",
        "        i = 0\n",
        "        while i < len(word):\n",
        "            try:\n",
        "                j = word.index(first, i)\n",
        "                new_word.extend(word[i:j])\n",
        "                i = j\n",
        "            except:\n",
        "                new_word.extend(word[i:])\n",
        "                break\n",
        "\n",
        "            if word[i] == first and i < len(word)-1 and word[i+1] == second:\n",
        "                new_word.append(first+second)\n",
        "                i += 2\n",
        "            else:\n",
        "                new_word.append(word[i])\n",
        "                i += 1\n",
        "        new_word = tuple(new_word)\n",
        "        word = new_word\n",
        "        print(\"word after merging: {}\".format(word))\n",
        "        if len(word) == 1:\n",
        "            break\n",
        "        else:\n",
        "            pairs = get_pairs(word)\n",
        "\n",
        "    # 특별 토큰인 </w>는 출력하지 않는다.\n",
        "    if word[-1] == '</w>':\n",
        "        word = word[:-1]\n",
        "    elif word[-1].endswith('</w>'):\n",
        "        word = word[:-1] + (word[-1].replace('</w>',''),)\n",
        "\n",
        "    return word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTPeYl9um9hN",
        "outputId": "bdac3f99-5c72-4dd2-fef5-69100e39b619"
      },
      "source": [
        "encode(\"loki\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__word split into characters:__ <tt>('l', 'o', 'k', 'i', '</w>')</tt>\n",
            "__Iteration 1:__\n",
            "bigrams in the word: {('o', 'k'), ('i', '</w>'), ('k', 'i'), ('l', 'o')}\n",
            "candidate for merging: ('l', 'o')\n",
            "word after merging: ('lo', 'k', 'i', '</w>')\n",
            "__Iteration 2:__\n",
            "bigrams in the word: {('i', '</w>'), ('lo', 'k'), ('k', 'i')}\n",
            "candidate for merging: ('i', '</w>')\n",
            "__Candidate not in BPE merges, algorithm stops.__\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('lo', 'k', 'i')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tNIBlGQn7Mz",
        "outputId": "a22636b3-27f0-43d2-a33e-4a6ff327d8b9"
      },
      "source": [
        "encode(\"lowest\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__word split into characters:__ <tt>('l', 'o', 'w', 'e', 's', 't', '</w>')</tt>\n",
            "__Iteration 1:__\n",
            "bigrams in the word: {('o', 'w'), ('w', 'e'), ('s', 't'), ('e', 's'), ('l', 'o'), ('t', '</w>')}\n",
            "candidate for merging: ('e', 's')\n",
            "word after merging: ('l', 'o', 'w', 'es', 't', '</w>')\n",
            "__Iteration 2:__\n",
            "bigrams in the word: {('o', 'w'), ('l', 'o'), ('es', 't'), ('w', 'es'), ('t', '</w>')}\n",
            "candidate for merging: ('es', 't')\n",
            "word after merging: ('l', 'o', 'w', 'est', '</w>')\n",
            "__Iteration 3:__\n",
            "bigrams in the word: {('est', '</w>'), ('o', 'w'), ('w', 'est'), ('l', 'o')}\n",
            "candidate for merging: ('est', '</w>')\n",
            "word after merging: ('l', 'o', 'w', 'est</w>')\n",
            "__Iteration 4:__\n",
            "bigrams in the word: {('w', 'est</w>'), ('o', 'w'), ('l', 'o')}\n",
            "candidate for merging: ('l', 'o')\n",
            "word after merging: ('lo', 'w', 'est</w>')\n",
            "__Iteration 5:__\n",
            "bigrams in the word: {('lo', 'w'), ('w', 'est</w>')}\n",
            "candidate for merging: ('lo', 'w')\n",
            "word after merging: ('low', 'est</w>')\n",
            "__Iteration 6:__\n",
            "bigrams in the word: {('low', 'est</w>')}\n",
            "candidate for merging: ('low', 'est</w>')\n",
            "__Candidate not in BPE merges, algorithm stops.__\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('low', 'est')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ncvEQVeotm6",
        "outputId": "cd731bab-f442-4731-a1a6-8c93af5bf0ba"
      },
      "source": [
        "encode(\"lowing\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__word split into characters:__ <tt>('l', 'o', 'w', 'i', 'n', 'g', '</w>')</tt>\n",
            "__Iteration 1:__\n",
            "bigrams in the word: {('w', 'i'), ('o', 'w'), ('i', 'n'), ('g', '</w>'), ('l', 'o'), ('n', 'g')}\n",
            "candidate for merging: ('l', 'o')\n",
            "word after merging: ('lo', 'w', 'i', 'n', 'g', '</w>')\n",
            "__Iteration 2:__\n",
            "bigrams in the word: {('lo', 'w'), ('w', 'i'), ('i', 'n'), ('g', '</w>'), ('n', 'g')}\n",
            "candidate for merging: ('lo', 'w')\n",
            "word after merging: ('low', 'i', 'n', 'g', '</w>')\n",
            "__Iteration 3:__\n",
            "bigrams in the word: {('low', 'i'), ('g', '</w>'), ('n', 'g'), ('i', 'n')}\n",
            "candidate for merging: ('low', 'i')\n",
            "__Candidate not in BPE merges, algorithm stops.__\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('low', 'i', 'n', 'g')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYW2LHmdpIJl",
        "outputId": "13e9a04c-df67-49bb-b7d6-772cad319b44"
      },
      "source": [
        "encode(\"highing\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__word split into characters:__ <tt>('h', 'i', 'g', 'h', 'i', 'n', 'g', '</w>')</tt>\n",
            "__Iteration 1:__\n",
            "bigrams in the word: {('i', 'n'), ('g', '</w>'), ('n', 'g'), ('h', 'i'), ('i', 'g'), ('g', 'h')}\n",
            "candidate for merging: ('i', 'n')\n",
            "__Candidate not in BPE merges, algorithm stops.__\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('h', 'i', 'g', 'h', 'i', 'n', 'g')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUicML8rzmB7"
      },
      "source": [
        "## IMDB리뷰 토큰화하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6oI_qn9zqBS"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import urllib.request\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNxXtzC2z3Ta",
        "outputId": "ff6ea172-8cc7-418c-d016-e9dc1379196c"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\", filename=\"IMDb_Reviews.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('IMDb_Reviews.csv', <http.client.HTTPMessage at 0x7fe1ff765650>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIruxaRvz9NS"
      },
      "source": [
        "train_df = pd.read_csv('IMDb_Reviews.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LBAEEml0FIp",
        "outputId": "8e22c5f9-6153-4335-fd3f-e2199d8cb553"
      },
      "source": [
        "train_df['review']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        My family and I normally do not watch local mo...\n",
              "1        Believe it or not, this was at one time the wo...\n",
              "2        After some internet surfing, I found the \"Home...\n",
              "3        One of the most unheralded great works of anim...\n",
              "4        It was the Sixties, and anyone with long hair ...\n",
              "                               ...                        \n",
              "49995    the people who came up with this are SICK AND ...\n",
              "49996    The script is so so laughable... this in turn,...\n",
              "49997    \"So there's this bride, you see, and she gets ...\n",
              "49998    Your mind will not be satisfied by this nobud...\n",
              "49999    The chaser's war on everything is a weekly sho...\n",
              "Name: review, Length: 50000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbU8mqTl0JSK",
        "outputId": "e6bca26f-c47e-40d8-ce37-76e17dedd17a"
      },
      "source": [
        "train_df['sentiment']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        1\n",
              "1        0\n",
              "2        0\n",
              "3        1\n",
              "4        0\n",
              "        ..\n",
              "49995    0\n",
              "49996    0\n",
              "49997    0\n",
              "49998    0\n",
              "49999    1\n",
              "Name: sentiment, Length: 50000, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tmmDcnF16FM"
      },
      "source": [
        "\n",
        "\n",
        "> Wordpiece Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0i96e2P0VGh"
      },
      "source": [
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(train_df['review'], target_vocab_size=2**13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvhYmskq0t63",
        "outputId": "3840d927-ac55-4424-aad7-313794dc1a0b"
      },
      "source": [
        "print(tokenizer.subwords[:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the_', ', ', '. ', 'a_', 'and_', 'of_', 'to_', 's_', 'is_', 'br', 'in_', 'I_', 'that_', 'this_', 'it_', ' /><', ' />', 'was_', 'The_', 't_', 'as_', 'with_', 'for_', '.<', 'on_', 'but_', 'movie_', 'are_', ' (', 'have_', 'his_', 'film_', 'not_', 'be_', 'you_', 'ing_', ' \"', 'ed_', 'it', 'd_', 'an_', 'at_', 'by_', 'he_', 'one_', 'who_', 'from_', 'y_', 'or_', 'e_', 'like_', 'all_', '\" ', 'they_', 'so_', 'just_', 'has_', ') ', 'about_', 'her_', 'out_', 'This_', 'some_', 'movie', 'ly_', 'film', 'very_', 'more_', 'It_', 'what_', 'would_', 'when_', 'if_', 'good_', 'up_', 'which_', 'their_', 'only_', 'even_', 'my_', 'really_', 'had_', 'can_', 'no_', 'were_', 'see_', '? ', 'she_', 'than_', '! ', 'there_', 'been_', 'get_', 'into_', 'will_', ' - ', 'much_', 'n_', 'because_', 'ing']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbfVMKTR2BDy",
        "outputId": "d73ec411-9dcb-4fac-bf2c-a7a3010aea8b"
      },
      "source": [
        "print(train_df['review'][20])\n",
        "# 21번째 샘플을 출력"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pretty bad PRC cheapie which I rarely bother to watch over again, and it's no wonder -- it's slow and creaky and dull as a butter knife. Mad doctor George Zucco is at it again, turning a dimwitted farmhand in overalls (Glenn Strange) into a wolf-man. Unfortunately, the makeup is virtually non-existent, consisting only of a beard and dimestore fangs for the most part. If it were not for Zucco and Strange's presence, along with the cute Anne Nagel, this would be completely unwatchable. Strange, who would go on to play Frankenstein's monster for Unuiversal in two years, does a Lenny impression from \"Of Mice and Men\", it seems.<br /><br />*1/2 (of Four)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIRI3OnQ2O9h",
        "outputId": "d0f8a3e0-270f-4e3d-c76f-dbba8ff5af42"
      },
      "source": [
        "print(\"토큰화된 샘플 질문 : {}\".format(tokenizer.encode(train_df['review'][20])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "토큰화된 샘플 질문 : [1590, 4162, 132, 7107, 1892, 2983, 578, 76, 12, 4632, 3422, 7, 160, 175, 372, 2, 5, 39, 8051, 8, 84, 2652, 497, 39, 8051, 8, 1374, 5, 3461, 2012, 48, 5, 2263, 21, 4, 2992, 127, 4729, 711, 3, 1391, 8044, 3557, 1277, 8102, 2154, 5681, 9, 42, 15, 372, 2, 3773, 4, 3502, 2308, 467, 4890, 1503, 11, 3347, 1419, 8127, 29, 5539, 98, 6099, 58, 94, 4, 1388, 4230, 8057, 213, 3, 1966, 2, 1, 6700, 8044, 9, 7069, 716, 8057, 6600, 2, 4102, 36, 78, 6, 4, 1865, 40, 5, 3502, 1043, 1645, 8044, 1000, 1813, 23, 1, 105, 1128, 3, 156, 15, 85, 33, 23, 8102, 2154, 5681, 5, 6099, 8051, 8, 7271, 1055, 2, 534, 22, 1, 3046, 5214, 810, 634, 8120, 2, 14, 71, 34, 436, 3311, 5447, 783, 3, 6099, 2, 46, 71, 193, 25, 7, 428, 2274, 2260, 6487, 8051, 8, 2149, 23, 1138, 4117, 6023, 163, 11, 148, 735, 2, 164, 4, 5277, 921, 3395, 1262, 37, 639, 1349, 349, 5, 2460, 328, 15, 5349, 8127, 24, 10, 16, 10, 17, 8054, 8061, 8059, 8062, 29, 6, 6607, 8126, 8053]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIdza5FY2kHZ",
        "outputId": "f7886800-f407-43a6-a82a-9df561b05bb5"
      },
      "source": [
        "sample_string1 = \"It's mind-blowing to me that this film was even made.\"\n",
        "\n",
        "# 인코딩해서 저장\n",
        "tokenized_string1 = tokenizer.encode(sample_string1)\n",
        "print('정수 인코딩 후의 문장 {}'.format(tokenized_string1))\n",
        "\n",
        "# 이를 다시 디코딩하자!\n",
        "oringinal_string = tokenizer.decode(tokenized_string1)\n",
        "print('기존 문장: {}'.format(oringinal_string))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정수 인코딩 후의 문장 [137, 8051, 8, 910, 8057, 2169, 36, 7, 103, 13, 14, 32, 18, 79, 681, 8058]\n",
            "기존 문장: It's mind-blowing to me that this film was even made.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yibtROju87R2",
        "outputId": "21fbb1aa-95be-47ef-dff2-0beff62b0566"
      },
      "source": [
        "sample_string2 = \"It's mind-blowing to me that this film was even made.\"\n",
        "\n",
        "# 인코딩해서 저장\n",
        "tokenized_string2 = tokenizer.encode(sample_string2)\n",
        "print('정수 인코딩 후의 문장 {}'.format(tokenized_string2))\n",
        "\n",
        "# 이를 다시 디코딩하자!\n",
        "oringinal_string = tokenizer.decode(tokenized_string2)\n",
        "print('기존 문장: {}'.format(oringinal_string))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정수 인코딩 후의 문장 [137, 8051, 8, 910, 8057, 2169, 36, 7, 103, 13, 14, 32, 18, 79, 681, 8058]\n",
            "기존 문장: It's mind-blowing to me that this film was even made.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8TH1p723NJr",
        "outputId": "4d8da893-8510-4505-d9e1-7e92d394e5b3"
      },
      "source": [
        "print('단어 집합의 크기(Vocab size) :', tokenizer.vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기(Vocab size) : 8268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrj1pUoa4qlz",
        "outputId": "ee4e9525-cc02-409f-a5c5-80e29173419a"
      },
      "source": [
        "for ts in tokenized_string1:\n",
        "  print('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "137 ----> It\n",
            "8051 ----> '\n",
            "8 ----> s \n",
            "910 ----> mind\n",
            "8057 ----> -\n",
            "2169 ----> blow\n",
            "36 ----> ing \n",
            "7 ----> to \n",
            "103 ----> me \n",
            "13 ----> that \n",
            "14 ----> this \n",
            "32 ----> film \n",
            "18 ----> was \n",
            "79 ----> even \n",
            "681 ----> made\n",
            "8058 ----> .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZfyr8Fg5JQK"
      },
      "source": [
        "sample_string = \"It's mind-blowing to me that this film was evenxyz made.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tgDmNOf6R7i",
        "outputId": "dbaf58b3-ea88-4f9c-cbee-037ba42b48bb"
      },
      "source": [
        "tokenized_string = tokenizer.encode(sample_string)\n",
        "print('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
        "\n",
        "#이를 다시 디코딩\n",
        "oringinal_string = tokenizer.decode(tokenized_string)\n",
        "print('기존 문장: {}'.format(oringinal_string))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정수 인코딩 후의 문장 [137, 8051, 8, 910, 8057, 2169, 36, 7, 103, 13, 14, 32, 18, 7974, 8132, 8133, 997, 681, 8058]\n",
            "기존 문장: It's mind-blowing to me that this film was evenxyz made.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsuclQkC6kMs",
        "outputId": "084baa99-5f34-4b18-b1d0-498e198bde00"
      },
      "source": [
        "for ts in tokenized_string:\n",
        "  print('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "137 ----> It\n",
            "8051 ----> '\n",
            "8 ----> s \n",
            "910 ----> mind\n",
            "8057 ----> -\n",
            "2169 ----> blow\n",
            "36 ----> ing \n",
            "7 ----> to \n",
            "103 ----> me \n",
            "13 ----> that \n",
            "14 ----> this \n",
            "32 ----> film \n",
            "18 ----> was \n",
            "79 ----> even \n",
            "681 ----> made\n",
            "8058 ----> .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_YR2n7VubTB"
      },
      "source": [
        "## 파이썬 TF-IDF 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIRhmG0B6tXw"
      },
      "source": [
        "import pandas as pd\n",
        "from math import log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RL9aOPeuscX"
      },
      "source": [
        "docs = [\n",
        "        '먹고 싶은 사과',\n",
        "        '먹고 싶은 바나나',\n",
        "        '길고 노란 바나나 바나나',\n",
        "        '저는 과일이 좋아요'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa6_5d6yu5s4"
      },
      "source": [
        "# 각 문장의 단어들을 리스트로 뽑는다.\n",
        "vocab = list(set(w for doc in docs for w in doc.split()))\n",
        "vocab.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrcyftw2vBHP",
        "outputId": "8dda6787-6bd6-46bc-8385-d62189da3ef0"
      },
      "source": [
        "print(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['과일이', '길고', '노란', '먹고', '바나나', '사과', '싶은', '저는', '좋아요']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMHfUEDUvHSg",
        "outputId": "8834a579-1c00-414f-c690-c88944019d21"
      },
      "source": [
        "#문장은 4개문장\n",
        "N = len(docs)\n",
        "print(N)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdSx4qUfxS_M"
      },
      "source": [
        "def tf(t,d):\n",
        "  return d.count(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSVIAYtcvX-A"
      },
      "source": [
        "# IDF 값 출력\n",
        "def idf(t):\n",
        "  df = 0\n",
        "  print(\"in idf->t->\",t)\n",
        "  \n",
        "  for doc in docs:\n",
        "   # print(\"doc->\",doc)\n",
        "    df += t in doc\n",
        "   # print(\"t->\",t)\n",
        "   # print(\"df->\", df)\n",
        "  return log(N/(df+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtsjWBNkvZ84"
      },
      "source": [
        "# TD-IDF 어떤 단어 t가 문장내에서 얼마나 중요한지 나타냄\n",
        "# TF(TERM FREQUENCY) 단어의 문서내에 출현한 횟수\n",
        "# IDF 그 단어가 출현한 문서의 숫자의 역수 -> IDF는 클수록 좋다 즉 DF는 작을 수록 좋다. 왜냐 'The'같은 의미없는단어\n",
        "def tfidf(t, d):\n",
        "  return tf(t,d)* idf(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "id": "0AbmrZedvpch",
        "outputId": "b5c43e96-8c6b-4a4e-c127-32a46c1b08a9"
      },
      "source": [
        "result = []\n",
        "# 4개 문장\n",
        "for i in range(N):\n",
        "  result.append([])\n",
        "  d = docs[i] #1번째 문장부터 순차적으로 처리\n",
        "  for j in range(len(vocab)): #첫번째 문장의 단어는 3개\n",
        "    t = vocab[j] # t에다 각 문장의 단어를 assign\n",
        "    result[-1].append(tfidf(t,d)) # t:단어 d:문장\n",
        "tfidf_ = pd.DataFrame(result, columns = vocab)\n",
        "tfidf_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "in idf->t-> 과일이\n",
            "in idf->t-> 길고\n",
            "in idf->t-> 노란\n",
            "in idf->t-> 먹고\n",
            "in idf->t-> 바나나\n",
            "in idf->t-> 사과\n",
            "in idf->t-> 싶은\n",
            "in idf->t-> 저는\n",
            "in idf->t-> 좋아요\n",
            "in idf->t-> 과일이\n",
            "in idf->t-> 길고\n",
            "in idf->t-> 노란\n",
            "in idf->t-> 먹고\n",
            "in idf->t-> 바나나\n",
            "in idf->t-> 사과\n",
            "in idf->t-> 싶은\n",
            "in idf->t-> 저는\n",
            "in idf->t-> 좋아요\n",
            "in idf->t-> 과일이\n",
            "in idf->t-> 길고\n",
            "in idf->t-> 노란\n",
            "in idf->t-> 먹고\n",
            "in idf->t-> 바나나\n",
            "in idf->t-> 사과\n",
            "in idf->t-> 싶은\n",
            "in idf->t-> 저는\n",
            "in idf->t-> 좋아요\n",
            "in idf->t-> 과일이\n",
            "in idf->t-> 길고\n",
            "in idf->t-> 노란\n",
            "in idf->t-> 먹고\n",
            "in idf->t-> 바나나\n",
            "in idf->t-> 사과\n",
            "in idf->t-> 싶은\n",
            "in idf->t-> 저는\n",
            "in idf->t-> 좋아요\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>과일이</th>\n",
              "      <th>길고</th>\n",
              "      <th>노란</th>\n",
              "      <th>먹고</th>\n",
              "      <th>바나나</th>\n",
              "      <th>사과</th>\n",
              "      <th>싶은</th>\n",
              "      <th>저는</th>\n",
              "      <th>좋아요</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.287682</td>\n",
              "      <td>0.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.575364</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        과일이        길고        노란  ...        싶은        저는       좋아요\n",
              "0  0.000000  0.000000  0.000000  ...  0.287682  0.000000  0.000000\n",
              "1  0.000000  0.000000  0.000000  ...  0.287682  0.000000  0.000000\n",
              "2  0.000000  0.693147  0.693147  ...  0.000000  0.000000  0.000000\n",
              "3  0.693147  0.000000  0.000000  ...  0.000000  0.693147  0.693147\n",
              "\n",
              "[4 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2otJe_RUwDaB"
      },
      "source": [
        "#docs = [\n",
        "#        '먹고 싶은 사과',\n",
        "#        '먹고 싶은 바나나',\n",
        "#        '길고 노란 바나나 바나나',\n",
        "#        '저는 과일이 좋아요'\n",
        "#]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6z_3yh4jyzEx"
      },
      "source": [
        "## 싸이킷런을 이용한 TF-IDF실습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBnKNzxLy1Sb"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPvnGBr5y-hu"
      },
      "source": [
        "corpus = [\n",
        "        '먹고 싶은 사과',\n",
        "        '먹고 싶은 바나나',\n",
        "        '길고 노란 바나나 바나나',\n",
        "        '저는 과일이 좋아요'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCbbIf6IzC9X",
        "outputId": "a725fe57-7756-4f64-c9c2-8d94b8dcc21e"
      },
      "source": [
        "tfidfv = TfidfVectorizer().fit(corpus)\n",
        "\n",
        "print(tfidfv.transform(corpus).toarray())\n",
        "print(tfidfv.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         0.52640543 0.         0.66767854\n",
            "  0.52640543 0.         0.        ]\n",
            " [0.         0.         0.         0.57735027 0.57735027 0.\n",
            "  0.57735027 0.         0.        ]\n",
            " [0.         0.47212003 0.47212003 0.         0.7444497  0.\n",
            "  0.         0.         0.        ]\n",
            " [0.57735027 0.         0.         0.         0.         0.\n",
            "  0.         0.57735027 0.57735027]]\n",
            "{'먹고': 3, '싶은': 6, '사과': 5, '바나나': 4, '길고': 1, '노란': 2, '저는': 7, '과일이': 0, '좋아요': 8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaMKTvyj0k9g"
      },
      "source": [
        "## 로이터 데이터로 TF-IDF 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-t1DGta0nfq"
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9V6LRB6A0zB4",
        "outputId": "89198dcc-0b26-444b-ffb6-6c37977464cf"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000, test_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/reuters.py:143: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/reuters.py:144: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XhH6Z8h1Je_",
        "outputId": "41a91e3b-6026-430b-8f83-752be2b7ab0d"
      },
      "source": [
        "print('훈련 샘플의 수 : {}'.format(len(x_train))) # 훈련 분류된 총 기사 갯수"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 샘플의 수 : 8982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd9jh1zs1UjG",
        "outputId": "ec119fd6-e3b4-405c-9269-81da7c169c08"
      },
      "source": [
        "print('테스트 샘플의 수 : {}'.format(len(x_test))) # 테스트 분류된 총 기사 갯수"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "테스트 샘플의 수 : 2246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Km-1Lr71aJv",
        "outputId": "dfe1c4d9-15c8-4b0f-ee9c-d708a8e437a7"
      },
      "source": [
        "print(type(x_train)) # x_train numpy type-> 2차원 행렬 행: 기사의 갯수  \n",
        "print(x_train)\n",
        "print(x_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "[list([1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12])\n",
            " list([1, 3267, 699, 3434, 2295, 56, 2, 7511, 9, 56, 3906, 1073, 81, 5, 1198, 57, 366, 737, 132, 20, 4093, 7, 2, 49, 2295, 2, 1037, 3267, 699, 3434, 8, 7, 10, 241, 16, 855, 129, 231, 783, 5, 4, 587, 2295, 2, 2, 775, 7, 48, 34, 191, 44, 35, 1795, 505, 17, 12])\n",
            " list([1, 53, 12, 284, 15, 14, 272, 26, 53, 959, 32, 818, 15, 14, 272, 26, 39, 684, 70, 11, 14, 12, 3886, 18, 180, 183, 187, 70, 11, 14, 102, 32, 11, 29, 53, 44, 704, 15, 14, 19, 758, 15, 53, 959, 47, 1013, 15, 14, 19, 132, 15, 39, 965, 32, 11, 14, 147, 72, 11, 180, 183, 187, 44, 11, 14, 102, 19, 11, 123, 186, 90, 67, 960, 4, 78, 13, 68, 467, 511, 110, 59, 89, 90, 67, 1390, 55, 2678, 92, 617, 80, 1274, 46, 905, 220, 13, 4, 346, 48, 235, 629, 5, 211, 5, 1118, 7, 2, 81, 5, 187, 11, 15, 9, 1709, 201, 5, 47, 3615, 18, 478, 4514, 5, 1118, 7, 232, 2, 71, 5, 160, 63, 11, 9, 2, 81, 5, 102, 59, 11, 17, 12])\n",
            " ...\n",
            " list([1, 141, 3890, 387, 81, 8, 16, 1629, 10, 340, 1241, 850, 31, 56, 3890, 691, 9, 1241, 71, 9, 5985, 2, 2, 699, 2, 2, 2, 699, 244, 5945, 4, 49, 8, 4, 656, 850, 33, 2993, 9, 2139, 340, 3371, 1493, 9, 2, 22, 2, 1094, 687, 83, 35, 15, 257, 6, 57, 9190, 7, 4, 5956, 654, 5, 2, 6191, 1371, 4, 49, 8, 16, 369, 646, 6, 1076, 7, 124, 407, 17, 12])\n",
            " list([1, 53, 46, 957, 26, 14, 74, 132, 26, 39, 46, 258, 3614, 18, 14, 74, 134, 5131, 18, 88, 2321, 72, 11, 14, 1842, 32, 11, 123, 383, 89, 39, 46, 235, 10, 864, 728, 5, 258, 44, 11, 15, 22, 753, 9, 42, 92, 131, 728, 5, 69, 312, 11, 15, 22, 222, 2, 3237, 383, 48, 39, 74, 235, 10, 864, 276, 5, 61, 32, 11, 15, 21, 4, 211, 5, 126, 1072, 42, 92, 131, 46, 19, 352, 11, 15, 22, 710, 220, 9, 42, 92, 131, 276, 5, 59, 61, 11, 15, 22, 10, 455, 7, 1172, 137, 336, 1325, 6, 1532, 142, 971, 6463, 43, 359, 5, 4, 326, 753, 364, 17, 12])\n",
            " list([1, 227, 2406, 91, 2, 125, 2855, 21, 4, 3976, 76, 7, 4, 757, 481, 3976, 790, 5259, 5654, 9, 111, 149, 8, 7, 10, 76, 223, 51, 4, 417, 8, 1047, 91, 6917, 1688, 340, 7, 194, 9411, 6, 1894, 21, 127, 2151, 2394, 1456, 6, 3034, 4, 329, 433, 7, 65, 87, 1127, 10, 8219, 1475, 290, 9, 21, 567, 16, 1926, 24, 4, 76, 209, 30, 4033, 6655, 5654, 8, 4, 60, 8, 4, 966, 308, 40, 2575, 129, 2, 295, 277, 1071, 9, 24, 286, 2114, 234, 222, 9, 4, 906, 3994, 8519, 114, 5758, 1752, 7, 4, 113, 17, 12])]\n",
            "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNvJJImy1kBg",
        "outputId": "e0c65535-cf98-4461-c19a-e70ae372f629"
      },
      "source": [
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8982,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGZl9l0U1xi3",
        "outputId": "2571d941-3824-40c2-fafd-0fb6b33ffa14"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 3  4  3 ... 25  3 25]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNuSZJiG1zUX",
        "outputId": "fe800020-c5a8-4932-fe9f-91a4e657b510"
      },
      "source": [
        "# 분류된 기사 종류의 수가 46개\n",
        "num_classes = max(y_train) + 1\n",
        "print('클래스의 수 : {}'.format(num_classes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "클래스의 수 : 46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ayr03SJr2Epn",
        "outputId": "7fea01a0-f7f5-499f-edc9-457cc3012ad5"
      },
      "source": [
        "print('훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in x_train))) # len(l)은 칼럼수 X_train 의 기사 중 가장 긴 길이의 수를 보여준다 각 행의 가장 큰 열의 갯수를 보여준다.\n",
        "print('훈련용 뉴스의 평균 길이 : {}'.format(sum(map(len, x_train))/len(x_train))) # "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련용 뉴스의 최대 길이 :2376\n",
            "훈련용 뉴스의 평균 길이 : 145.5398574927633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "BN8Vh34H2Uqv",
        "outputId": "b0fc9695-c4bd-4937-e1fd-0e2724a3200c"
      },
      "source": [
        "\n",
        "plt.hist([len(s) for s in x_train], bins= 50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "vAV9cwDA20FI",
        "outputId": "14d7975e-7afa-4027-876a-2ca91dc86c90"
      },
      "source": [
        "fig, axe = plt.subplots(ncols= 1)\n",
        "fig.set_size_inches(12, 5)\n",
        "sns.countplot(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff50254d990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAAEvCAYAAAB7WWYEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7xkVXXg8d+CRhRfQGhaBJwm2ibBJKLTQUyMQYi8NDQgEogPRByMQkRjxkAyIyrDxEeQEaMkKAgoisiz1TaABGMyo0CjgN0g0CqG7vBoBcEMH3Ea1/xxdkN5qTp1zr13d997+X0/n/rcU7v2qr2rat2qVad2nYrMRJIkSdL02mRjT0CSJEmaiyy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQK5m3sCdSwzTbb5MKFCzf2NCRJkjTHXXfddT/KzPnDLpuThfbChQtZvnz5xp6GJEmS5riI+OGoy1w6IkmSJFVgoS1JkiRVYKEtSZIkVWChLUmSJFVgoS1JkiRVYKEtSZIkVWChLUmSJFVgoS1JkiRVYKEtSZIkVWChLUmSJFVgoS1JkiRVMG9jT0CP+vePvbNz32cefXLFmUiSJGmq3KMtSZIkVWChLUmSJFVgoS1JkiRVYKEtSZIkVWChLUmSJFVgoS1JkiRVYKEtSZIkVWChLUmSJFVQrdCOiCdGxDURcUNErIyI95b2nSLi6ohYFRGfj4gnlPbNy/lV5fKFA9d1fGm/JSL2rjVnSZIkabrU3KP9ELBHZj4f2AXYJyJ2Az4AnJKZzwHuA44s/Y8E7ivtp5R+RMTOwKHA84B9gI9HxKYV5y1JkiRNWbVCOxv/Uc5uVk4J7AFcUNrPBg4o20vKecrle0ZElPbzMvOhzPwBsArYtda8JUmSpOlQdY12RGwaEdcD9wBXAN8DfpKZ60qX1cD2ZXt74A6Acvn9wK8Mtg+JkSRJkmakqoV2Zj6cmbsAO9Dshf71WmNFxFERsTwilq9du7bWMJIkSVInG+SoI5n5E+Aq4MXAlhExr1y0A7CmbK8BdgQolz8d+PFg+5CYwTFOz8zFmbl4/vz5VW6HJEmS1FXNo47Mj4gty/aTgJcDN9MU3AeXbocDl5btpeU85fJ/ysws7YeWo5LsBCwCrqk1b0mSJGk6zBvfZdK2A84uRwjZBDg/M78UETcB50XE/wC+DZxR+p8BfDoiVgH30hxphMxcGRHnAzcB64CjM/PhivOWJEmSpqxaoZ2ZNwIvGNL+fYYcNSQzfwa8esR1nQScNN1zlCRJkmrxlyElSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAqqFdoRsWNEXBURN0XEyog4trS/JyLWRMT15bTfQMzxEbEqIm6JiL0H2vcpbasi4rhac5YkSZKmy7yK170OeGdmfisingpcFxFXlMtOycy/HewcETsDhwLPA54JfDUinlsu/hjwcmA1cG1ELM3MmyrOXZIkSZqSaoV2Zt4J3Fm2fxoRNwPbt4QsAc7LzIeAH0TEKmDXctmqzPw+QEScV/paaEuSJGnG2iBrtCNiIfAC4OrSdExE3BgRZ0bEVqVte+COgbDVpW1UuyRJkjRjVS+0I+IpwIXA2zPzAeA04NnALjR7vE+epnGOiojlEbF87dq103GVkiRJ0qRVLbQjYjOaIvvczLwIIDPvzsyHM/MXwCd4dHnIGmDHgfAdStuo9l+Smadn5uLMXDx//vzpvzGSJElSDzWPOhLAGcDNmfnhgfbtBrodCKwo20uBQyNi84jYCVgEXANcCyyKiJ0i4gk0X5hcWmvekiRJ0nSoedSR3wNeB3wnIq4vbX8FHBYRuwAJ3A68GSAzV0bE+TRfclwHHJ2ZDwNExDHAZcCmwJmZubLivCVJkqQpq3nUkX8FYshFy1piTgJOGtK+rC1OkiRJmmn8ZUhJkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqYJqhXZE7BgRV0XETRGxMiKOLe1bR8QVEXFb+btVaY+IODUiVkXEjRHxwoHrOrz0vy0iDq81Z0mSJGm61NyjvQ54Z2buDOwGHB0ROwPHAVdm5iLgynIeYF9gUTkdBZwGTWEOnAC8CNgVOGF9cS5JkiTNVNUK7cy8MzO/VbZ/CtwMbA8sAc4u3c4GDijbS4BzsvFNYMuI2A7YG7giM+/NzPuAK4B9as1bkiRJmg4bZI12RCwEXgBcDSzIzDvLRXcBC8r29sAdA2GrS9uodkmSJGnGql5oR8RTgAuBt2fmA4OXZWYCOU3jHBURyyNi+dq1a6fjKiVJkqRJq1poR8RmNEX2uZl5UWm+uywJofy9p7SvAXYcCN+htI1q/yWZeXpmLs7MxfPnz5/eGyJJkiT1VPOoIwGcAdycmR8euGgpsP7IIYcDlw60v74cfWQ34P6yxOQyYK+I2Kp8CXKv0iZJkiTNWPMqXvfvAa8DvhMR15e2vwLeD5wfEUcCPwQOKZctA/YDVgEPAkcAZOa9EXEicG3p977MvLfivCVJkqQpq1ZoZ+a/AjHi4j2H9E/g6BHXdSZw5vTNbm65/dQDxncasPBtl1SaiSRJktbzlyElSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAo6FdoRcWWXNkmSJEmNeW0XRsQTgS2AbSJiKyDKRU8Dtq88N0mSJGnWai20gTcDbweeCVzHo4X2A8DfVZyXJEmSNKu1FtqZ+RHgIxHxZ5n50Q00J0mSJGnWG7dHG4DM/GhE/C6wcDAmM8+pNC9JkiRpVutUaEfEp4FnA9cDD5fmBCy0JUmSpCE6FdrAYmDnzMyak5EkSZLmiq7H0V4BPKPmRCRJkqS5pOse7W2AmyLiGuCh9Y2ZuX+VWUmSJEmzXNdC+z01JyFJkiTNNV2POvLPtSciSZIkzSVdjzryU5qjjAA8AdgM+L+Z+bRaE5MkSZJms657tJ+6fjsiAlgC7FZrUpIkSdJs1/WoI4/IxiXA3hXmI0mSJM0JXZeOHDRwdhOa42r/rMqMJEmSpDmg61FH/mhgex1wO83yEUmSJElDdF2jfUTtiUiSJElzSac12hGxQ0RcHBH3lNOFEbFD7clJkiRJs1XXL0N+ClgKPLOcvljaJEmSJA3RtdCen5mfysx15XQWML/ivCRJkqRZrWuh/eOIeG1EbFpOrwV+XHNikiRJ0mzWtdB+I3AIcBdwJ3Aw8Ia2gIg4s6znXjHQ9p6IWBMR15fTfgOXHR8RqyLilojYe6B9n9K2KiKO63HbJEmSpI2ma6H9PuDwzJyfmdvSFN7vHRNzFrDPkPZTMnOXcloGEBE7A4cCzysxH1+/9xz4GLAvsDNwWOkrSZIkzWhdC+3fzsz71p/JzHuBF7QFZObXgXs7Xv8S4LzMfCgzfwCsAnYtp1WZ+f3M/DlwHh6/W5IkSbNA10J7k4jYav2ZiNia7j92M9ExEXFjWVqy/jq3B+4Y6LO6tI1qlyRJkma0roX2ycA3IuLEiDgR+D/ABycx3mnAs4FdaNZ6nzyJ6xgqIo6KiOURsXzt2rXTdbWSJEnSpHQqtDPzHOAg4O5yOigzP913sMy8OzMfzsxfAJ+gWRoCsAbYcaDrDqVtVPuw6z49Mxdn5uL58z3yoCRJkjauzss/MvMm4KapDBYR22XmneXsgcD6I5IsBT4bER+m+UGcRcA1QACLImInmgL7UOBPpjIHSZIkaUOY7DrrsSLic8DuwDYRsRo4Adg9InYBErgdeDNAZq6MiPNpCvl1wNGZ+XC5nmOAy4BNgTMzc2WtOUuSJEnTpVqhnZmHDWk+o6X/ScBJQ9qXAcumcWqSJElSdV2/DClJkiSpBwttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqYJqhXZEnBkR90TEioG2rSPiioi4rfzdqrRHRJwaEasi4saIeOFAzOGl/20RcXit+UqSJEnTqeYe7bOAfSa0HQdcmZmLgCvLeYB9gUXldBRwGjSFOXAC8CJgV+CE9cW5JEmSNJNVK7Qz8+vAvROalwBnl+2zgQMG2s/JxjeBLSNiO2Bv4IrMvDcz7wOu4LHFuyRJkjTjbOg12gsy886yfRewoGxvD9wx0G91aRvVLkmSJM1oG+3LkJmZQE7X9UXEURGxPCKWr127drquVpIkSZqUDV1o312WhFD+3lPa1wA7DvTbobSNan+MzDw9Mxdn5uL58+dP+8QlSZKkPjZ0ob0UWH/kkMOBSwfaX1+OPrIbcH9ZYnIZsFdEbFW+BLlXaZMkSZJmtHm1rjgiPgfsDmwTEatpjh7yfuD8iDgS+CFwSOm+DNgPWAU8CBwBkJn3RsSJwLWl3/syc+IXLCVJkqQZp1qhnZmHjbhozyF9Ezh6xPWcCZw5jVOTJEmSqvOXISVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCiy0JUmSpAostCVJkqQKLLQlSZKkCuZtjEEj4nbgp8DDwLrMXBwRWwOfBxYCtwOHZOZ9ERHAR4D9gAeBN2TmtzbGvCU9fu138Qd79V924LsqzUSSNFtszD3aL8vMXTJzcTl/HHBlZi4CriznAfYFFpXTUcBpG3ymkiRJUk8zaenIEuDssn02cMBA+znZ+CawZURstzEmKEmSJHW1sQrtBC6PiOsi4qjStiAz7yzbdwELyvb2wB0DsatLmyRJkjRjbZQ12sBLMnNNRGwLXBER3x28MDMzIrLPFZaC/SiAZz3rWdM3U0mSJGkSNsoe7cxcU/7eA1wM7ArcvX5JSPl7T+m+BthxIHyH0jbxOk/PzMWZuXj+/Pk1py9JkiSNtcEL7Yh4ckQ8df02sBewAlgKHF66HQ5cWraXAq+Pxm7A/QNLTCRJkqQZaWMsHVkAXNwctY95wGcz8x8j4lrg/Ig4EvghcEjpv4zm0H6raA7vd8SGn7IkSZLUzwYvtDPz+8Dzh7T/GNhzSHsCR2+AqUnawPZdun/nvl/Zf2nFmUiSNP021pchZ7S1f/8PvfrP/9M3V5qJJEmSZquZdBxtSZIkac6w0JYkSZIqsNCWJEmSKnCNtlTJGefs1av/ka+/vNJMJEnSxuAebUmSJKkCC21JkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqQILbUmSJKkCC21JkiSpAgttSZIkqQJ/GVKSKnvFRaf26v/lg95WaSaSpA3JPdqSJElSBRbakiRJUgUW2pIkSVIFFtqSJElSBRbakiRJUgUW2pIkSVIFFtqSJElSBR5HW5pDPvi5vXv1f9dhl1WaiSRJco+2JEmSVIF7tDVrfOWM/Xr13/fIZZVmIkmSNJ57tCVJkqQK3KMttTj3rH5rnl/zBtc8S5Kkhnu0JUmSpArco63HhYs+tU+v/gcd8Y+VZiL184oL/6Fz3y+/6s0VZ1LXH11waee+Xzx4ScWZSNL0cY+2JEmSVIF7tKfZ3ad9sFf/BW95V6WZSBpmv4tP6NV/2YHvrTQTSdJcN6cL7bWnfaZX//lveW2lmUjS3PfKC77Qq/+XDn51pZlI0swwawrtiNgH+AiwKfDJzHz/Rp7S49rV//DKXv1f9OYvVZrJ3PR3n+l+tJNjXuuRTjS9XnnBuZ37fung11Scycx00IXf6NX/ole9eFrG/eOLvt+57+cP+tVpGXNjuPQLP+rcd8mrt5mWMb9x9tpe/V98+PxpGVdz36wotCNiU+BjwMuB1cC1EbE0M2/auDOTtDHse8nbevX/ygGnVpqJNPMdf/GaXv3/5sDtH9n+yMV3dY479sBn9BpHG95dJ9/Wq/8z3rnoke27T7mhc9yCdzy/1zhz2awotIFdgVWZ+X2AiDgPWAJYaE/Rdz6+f+e+v/XWpdMy5lWffEXnvi9705enZUyN99/P735klhMPefSoLG+9qN8RXT5+kEd00fRZckG/fLr04H75Ot0OvrB7sQJwwassWGayGz5xT6/+z/8v2z6yveqjd/eKfc6fLXhk+84P3Nk5bru/3K7XODPJ3ad+rXPfBW/bfVrGvOdjF/fqv+3RB7ZePlsK7e2BOwbOrwZetJHmIkkz3isvPKtX/y+96g1V5jGTHXDhVb36X/Kql1Waydzz6Yv6LcV43UFTX4rx1c/2G/MP/8TlHxvC3R/5Zq/+C47dbcpj3vN3X+nVf9tj9p3ymKNEZla78ukSEQcD+2Tmm8r51wEvysxjBvocBRxVzv4acEvLVW4DdF8ENvW42TbmVGIdc26NOZVYx5xbY04l1jHn1phTiXXMuTXmVGLn0pj/KTOHv3PLzBl/Al4MXDZw/njg+Clc3/INGTfbxpxt83XMmRnrmHNrzNk2X8ecmbGOObfGnG3z3RhjzpYfrLkWWBQRO0XEE4BDgelZMCxJkiRVMCvWaGfmuog4BriM5vB+Z2bmyo08LUmSJGmkWVFoA2TmMmDZNF3d6Rs4braNOZVYx5xbY04l1jHn1phTiXXMuTXmVGIdc26NOZXYx8WYs+LLkJIkSdJsM1vWaEuSJEmzyuOq0I6IfSLilohYFRHH9Yg7MyLuiYgVPcfbMSKuioibImJlRBzbI/aJEXFNRNxQYt/bc+xNI+LbEdHrt88j4vaI+E5EXB8Ry3vGbhkRF0TEdyPi5ogY+7vDEfFrZaz1pwci4u09xnxHuX9WRMTnIuKJHeOOLTErx4037PGPiK0j4oqIuK383apH7KvLuL+IiMU94j5U7tsbI+LiiNiyR+yJJe76iLg8Ip7ZJW7gsndGREbE0N87HjHmeyJizcBju1/XMSPiz8ptXRkRH+wx5ucHxrs9Iq7vEbtLRHxzfe5HxK4d454fEd8o/zdfjIinDYkb+lzQJY9aYlvzqCVubB61xHbJo9bnvVG51DJmlzwaOWZbLrWMOTaPWmJb86glrkseDX1diOZAAVdH89r2+WgOGtAl7pgS0/a/PSr23GheT1dE83+xWY/YM0rbjdG8ZjylS9zA5adGxH/0nO9ZEfGDgcd1l45xEREnRcSt0byuPeZnaVti/2VgvH+PiEs6xu0ZEd8qcf8aEc/pMeYeJXZFRJwdEUOXCMeEGmFcDo2JHZtHI+LG5lBLbGsOjYobaB+ZQy1jtubQSJM9zMlsO9F8ifJ7wK8CTwBuAHbuGPtS4IXAip5jbge8sGw/Fbi1x5gBPKVsbwZcDezWY+w/Bz4LfKnnnG8HtpnkfXw28Kay/QRgy0k8RnfRHI+yS//tgR8ATyrnzwfe0CHuN4EVwBY031P4KvCcPo8/8EHguLJ9HPCBHrG/QXOs968Bi3vE7QXMK9sf6Dnm0wa23wb8fdc8B3ak+SLyD0flxogx3wP8xZjHYljcy8pjsnk5v23X2AmXnwy8u8e4lwP7lu39gK91jLsW+IOy/UbgxCFxQ58LuuRRS2xrHrXEjc2jltgueTTyea8tl1rG7JJHo2Jbc6ltruPyqGXM1jxqieuSR0NfF2ie+w4t7X8PvKVj3AuAhbQ877fE7lcuC+BzE8ccEzuYRx+m/A+MiyvnFwOfBv6j53zPAg5uyaFRcUcA5wCbDMuhcfMd6HMh8PqOY94K/EZpfytwVscxf5fmx/2eW9rfBxw54vb+Uo0wLofGxI7NoxFxY3OoJbY1h0bFdcmhljFbc2jU6fG0R/uRn3HPzJ8D63/GfazM/Dpwb98BM/POzPxW2f4pcDNNcdglNjNz/butzcqp04L6iNgBeAXwyb5znqyIeDpNEXIGQGb+PDN/0vNq9gS+l5k/7BEzD3hSede+BfDvHWJ+A7g6Mx/MzHXAPwMHjeo84vFfQvPGgvL3gK6xmXlzZrb9oNKouMvLfAG+CezQI/aBgbNPZkguteT5KcC7hsV0iG01Iu4twPsz86HSZ+hvHLeNGREBHELz5N01NoH1exGfzpBcGhH3XODrZfsK4FVD4kY9F4zNo1Gx4/KoJW5sHrXEdsmjtue9kbk0xefLUbGtuTRuzLY8aoltzaOWuC55NOp1YQ/ggtL+mDwaFZeZ387M2yeO0zF2WbksgWsYnkejYh+AR+7fJzEhH0bFRcSmwIdocqjXfNtu45i4twDvy8xflH6PeT4aN2Y0n07sAVzSMa7Lc9Gw2IeBn2fmraV9aB5NrBHK49CaQ6Niy1zG5tGIuLE51BLbmkOj4rrk0KjYyXo8FdrDfsa905P4dIiIhTTv+q7uEbNpNB9Z3gNckZldY/8XTRL9ouc0oUnWyyPiumh+bbOrnYC1wKfKRy2fjIgn9xz7UEYURkMnmrkG+Fvg34A7gfsz8/IOoSuA34+IX4mILWjeVe/Yc64LMvPOsn0XsKBn/FS9Eej1G7Pl4887gNcA7+4YswRYk5k39J8iAMeUj/bOjBHLa4Z4Ls3jc3VE/HNE/M4kxv194O7MvK1HzNuBD5X76G9pfhiri5U8+qb91YzJpQnPBb3yaDLPI2PixubRxNg+eTQY2yeXhsy3cx5NiO2cSyPuo055NCG2cx5NiOuURxNfF2g+qf3JwJunoa9tU3g9aY0tH/e/DvjHPrER8SmanP914KMd444Blg78z/Sd70klj06JiM07xj0b+ONolgF9JSIW9b2PaIrWKye8UW2LexOwLCJW09y37+8yJk2xOi8eXUp2MMPzaGKN8Ct0yKERsV2NjBuXQ6Nix+XQiLhOOdQy39YcGubxVGhvNGXt0IXA24f9o42SmQ9n5i407/J2jYjf7DDWK4F7MvO6SU73JZn5QmBf4OiIeGnHuHk0H6mflpkvAP4vzUfhnUSzHmx/4As9YraieWHaCXgm8OSIeO24uMy8meYj88tp/rGvp9kTMCnl3XinTxumQ0T8NbAOOLdPXGb+dWbuWOKO6TDOFsBf0bEoH+I0mhepXWjeCJ3cMW4esDXNR6j/FTi/7LXo4zB6vGkr3gK8o9xH76B8OtPBG4G3RsR1NEsBfj6qY9tzwbg8muzzyKi4Lnk0LLZrHg3GlnE65dKQMTvn0ZDYTrnUct+OzaMhsZ3yaEhcpzya+LpAU2SMNZnXk46xHwe+npn/0ic2M4+ged6+GfjjDnEvpXkDMqyg6jLm8TT31e/Q5MRfdozbHPhZZi4GPgGc2ed2FiPzaETcO4D9MnMH4FM0SyPGxgLPo9lhdUpEXAP8lAmvbVOpESYb2yFuZA61xbbl0LC4aL5TMjaHWsYcm0NDZc+1JrP1xBR/xp1m/VGvNdolbjOaNYl/PsX5v5sx6xRLv7+heTd6O807vQeBz0xyzPd0GbP0fQZw+8D53we+3GOsJcDlPef3auCMgfOvBz4+idv5P4G39nn8gVuA7cr2dsAtfXOHljXao+KANwDfALboM98Jlz2r5bJH4oDfotlTcns5raP59OAZkxiz82U0b35eNnD+e8D8HvfRPOBuYIeej+n98MghTwN4YBK35bnANSMue8xzQdc8GhbbJY9GxXXJo7YxO+TRL8V2zaUOY7bd98Pu37G51HIfjc2jEWOOzaMOt3NkHk3o926aNxA/4tF197/0WtcS9xcD52+n43dzBmOBE2iWQ2zSN3ag7aWM+S5RiTuB5jVtfQ79gmY56GTG3L3jmH8BfBfYaeDxvL/nfbQN8GPgiT0ez+8NtD0LuGmSt3Mv4PwJbcNqhHO75NCI2M8MXD40j9rixuXQuDFH5dCIuPu65FDHMcfm0PrT42mP9gb/Gfey5+QM4ObMHPqOtCV2fpSjAUTEk4CX0/zDt8rM4zNzh8xcSHMb/ykzx+7lLeM8OSKeun6b5p+005FWMvMu4I6I+LXStCdwU5fYYjJ7IP8N2C0itij39Z4072zHiohty99n0azP/mzPsZcCh5ftw4FLe8b3FhH70HyUtX9mPtgzdvDjziV0y6XvZOa2mbmw5NNqmi9x3dVxzO0Gzh5Ix1yiedJ9WbmO59J8sfZHHWMB/hD4bmau7hEDzTrIPyjbewCdlp0M5NImwH+j+SLRxD6jngvG5tFkn0dGxXXJo5bYsXk0LLZLLrWMOTaPWu6j1lwac9+25lFLbGsetdzOLnk07HXhZuAqmmUCMCSPJvt60hYbEW8C9gYOy7J+uWPsLVGOolHui23qkFMAAAJeSURBVP0nzmVE3HWZ+YyBHHowM4cdjWPUfLcbGPMAJuRRy330SA7RPK63MsGY+/dgmoLsZx3jbgaeXvKVgbaut3N9Hm1Os8f1l/JoRI3wGsbkUEtsl0+Rh8Z1yaFhscDrxuXQiDG36pJDLfNtzaG2O+Bxc6JZi3srzV6Nv+4R9zmajyz/H80LxNBv8Q6JewnNR8E30ixPuJ7m46Ausb8NfLvErmDE0RPGXMfu9DjqCM0RWW4op5V97qMSvwuwvMz5EmCrjnFPpnnH//RJ3Mb3ln+wFTTfIt68Y9y/0LwRuAHYs+/jT7Om7UqaF9GvAlv3iD2wbD9Es8ds2J6DYXGraL5nsD6XHnPEh5bYC8t9dCPwRZovtvXKc9qPTDBszE8D3yljLqXsue0Q9wTgM2W+3wL26PN/SfPN8D+dxGP6EuC6khNXA/+5Y9yxNM8rt9KspYwhcUOfC7rkUUtsax61xI3No5bYLnk09nlvWC61jNklj0bFtuZS21zH5VHLmK151BLXJY+Gvi7QPHdfUx7bLzDhebAl7m0lh9bRvEH4ZI8x19G8lq6/DcOOzPKYWJolq/+7PKYraPamPq3LmBP6jDrqyKj5/tPAmJ+hHLGjQ9yWwJdL7DeA53cds1z2NWCfnnM9sIx3Q4n/1R6xH6IpzG+hWZbU9jy4O48eUaM1h8bEjs2jEXFjc2hYbJccGjVmlxxqmW9rDo06+cuQkiRJUgWPp6UjkiRJ0gZjoS1JkiRVYKEtSZIkVWChLUmSJFVgoS1JkiRVYKEtSZIkVWChLUmSJFVgoS1JkiRV8P8BgTpY6EFbXc0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWNwK0Yw3YPh",
        "outputId": "e4aec0a4-0bc2-4e01-ca77-ad3df098bc71"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
        "print(\"각 클래스 빈도수 : \")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "각 클래스 빈도수 : \n",
            "[[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
            "    14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
            "    28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
            "    42   43   44   45]\n",
            " [  55  432   74 3159 1949   17   48   16  139  101  124  390   49  172\n",
            "    26   20  444   39   66  549  269  100   15   41   62   92   24   15\n",
            "    48   19   45   39   32   11   50   10   49   19   19   24   36   30\n",
            "    13   21   12   18]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUdw57Vh342u",
        "outputId": "39550b3f-596c-4def-d343-6ea73fb306aa"
      },
      "source": [
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lg9KwY_z4myw",
        "outputId": "78f37028-7c1b-4e15-c6f3-9eb0c9874c75"
      },
      "source": [
        "word_index['the']"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lLjY5JI4twP",
        "outputId": "e7d1b064-4afc-4f90-b7cb-4fab53d04193"
      },
      "source": [
        "word_index['it']"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb3f-kFd4yun"
      },
      "source": [
        "index_to_word = {index +3 : word for word, index in word_index.items()}"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syvFEnlx5SwO",
        "outputId": "ec952f69-1477-4606-d08a-61aec9a6ad18"
      },
      "source": [
        "print(index_to_word[4])\n",
        "print(index_to_word[16])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the\n",
            "it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ3HMJ8n5dO3"
      },
      "source": [
        "# 로이터의 데이타 특성을 위해 3가지 종류를 index_to_word에 추가\n",
        "# 0 <pad>\n",
        "# 1 <sos>\n",
        "# 2 <unk>\n",
        "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
        "  index_to_word[index] = token"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYwE7OlH530X",
        "outputId": "609f13d8-01e6-4e91-b7a1-df009b735ffc"
      },
      "source": [
        "print(x_train[0])\n",
        "print(' '.join([index_to_word[index] for index in x_train[0]]))\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
            "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa7fAEkj6Kb3"
      },
      "source": [
        "decoded = []\n",
        "for i in range(len(x_train)):\n",
        "  t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
        "  decoded.append(t)\n",
        "\n",
        "x_train = decoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNZSkWl1DKTB"
      },
      "source": [
        "decoded = []\n",
        "for i in range(len(x_test)):\n",
        "  t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
        "  decoded.append(t)\n",
        "\n",
        "x_test = decoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP9idKeCDZ8d",
        "outputId": "a78878e6-137d-4d37-8e0e-c842ad891fb0"
      },
      "source": [
        "x_train[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3',\n",
              " '<sos> generale de banque sa lt <unk> br and lt heller overseas corp of chicago have each taken 50 pct stakes in <unk> company sa <unk> factors generale de banque said in a statement it gave no financial details of the transaction sa <unk> <unk> turnover in 1986 was 17 5 billion belgian francs reuter 3',\n",
              " '<sos> shr 3 28 dlrs vs 22 cts shr diluted 2 99 dlrs vs 22 cts net 46 0 mln vs 3 328 000 avg shrs 14 0 mln vs 15 2 mln year shr 5 41 dlrs vs 1 56 dlrs shr diluted 4 94 dlrs vs 1 50 dlrs net 78 2 mln vs 25 9 mln avg shrs 14 5 mln vs 15 1 mln note earnings per share reflect the two for one split effective january 6 1987 per share amounts are calculated after preferred stock dividends loss continuing operations for the qtr 1986 includes gains of sale of investments in <unk> corp of 14 mln dlrs and associated companies of 4 189 000 less writedowns of investments in national <unk> inc of 11 8 mln and <unk> corp of 15 6 mln reuter 3',\n",
              " \"<sos> the farmers home administration the u s agriculture department's farm lending arm could lose about seven billion dlrs in outstanding principal on its severely <unk> borrowers or about one fourth of its farm loan portfolio the general accounting office gao said in remarks prepared for delivery to the senate agriculture committee brian crowley senior associate director of gao also said that a preliminary analysis of proposed changes in <unk> financial eligibility standards indicated as many as one half of <unk> borrowers who received new loans from the agency in 1986 would be <unk> under the proposed system the agency has proposed evaluating <unk> credit using a variety of financial ratios instead of relying solely on <unk> ability senate agriculture committee chairman patrick leahy d vt <unk> the proposed eligibility changes telling <unk> administrator <unk> clark at a hearing that they would mark a dramatic shift in the agency's purpose away from being farmers' lender of last resort toward becoming a big city bank but clark defended the new regulations saying the agency had a responsibility to <unk> its 70 billion dlr loan portfolio in a <unk> yet <unk> manner crowley of gao <unk> <unk> arm said the proposed credit <unk> system attempted to ensure that <unk> would make loans only to borrowers who had a reasonable change of repaying their debt reuter 3\",\n",
              " '<sos> seton co said its board has received a proposal from chairman and chief executive officer philip d <unk> to acquire seton for 15 75 dlrs per share in cash seton said the acquisition bid is subject to <unk> arranging the necessary financing it said he intends to ask other members of senior management to participate the company said <unk> owns 30 pct of seton stock and other management members another 7 5 pct seton said it has formed an independent board committee to consider the offer and has deferred the annual meeting it had scheduled for march 31 reuter 3']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEt6OgnADhjN",
        "outputId": "833da57a-2e62-445d-c009-5879bb57d0bb"
      },
      "source": [
        "x_test[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos> the great atlantic and pacific tea co said its three year 345 mln dlr capital program will be be substantially increased to <unk> growth and expansion plans for <unk> inc and <unk> inc over the next two years a and p said the acquisition of <unk> in august 1986 and <unk> in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 48 3 pct to 1 58 billion dlrs a and p gave no details on the expanded capital program but it did say it completed the first year of the program during 1986 a and p is 52 4 pct owned by lt <unk> <unk> of west germany reuter 3',\n",
              " \"<sos> philippine sugar production in the 1987 88 crop year ending august has been set at 1 6 mln tonnes up from a provisional 1 3 mln tonnes this year sugar regulatory administration <unk> chairman <unk> yulo said yulo told reuters a survey during the current milling season which ends next month showed the 1986 87 estimate would almost certainly be met he said at least 1 2 mln tonnes of the 1987 88 crop would be earmarked for domestic consumption yulo said about 130 000 tonnes would be set aside for the u s sugar quota 150 000 tonnes for strategic reserves and 50 000 tonnes would be sold on the world market he said if the government approved a long standing <unk> recommendation to manufacture ethanol the project would take up another 150 000 tonnes slightly raising the target the government for its own reasons has been delaying approval of the project but we expect it to come through by july yulo said ethanol could make up five pct of gasoline cutting the oil import bill by about 300 mln pesos yulo said three major philippine <unk> were ready to start manufacturing ethanol if the project was approved the ethanol project would result in employment for about 100 000 people sharply reducing those thrown out of work by depressed world sugar prices and a <unk> domestic industry production quotas set for the first time in 1987 88 had been submitted to president corazon aquino i think the president would rather wait <unk> the new congress <unk> after the may elections he said but there is really no need for such quotas we are right now producing just slightly over our own consumption level the producers have never enjoyed such high prices yulo said adding sugar was currently selling locally for 320 pesos per <unk> up from 190 pesos last august yulo said prices were driven up because of speculation following the <unk> bid to control production we are no longer concerned so much with the world market he said adding producers in the <unk> region had learned from their <unk> and diversified into corn and <unk> farming and <unk> production he said diversification into products other than ethanol was also possible within the sugar industry the <unk> long ago <unk> their <unk> yulo said they have 300 sugar mills compared with our 41 but they <unk> many of them and diversified production we want to call this a <unk> <unk> instead of the sugar industry he said sugarcane could be fed to pigs and livestock used for <unk> <unk> or used in room <unk> when you cut sugarcane you don't even have to produce sugar he said yulo said the philippines was lobbying for a renewal of the international sugar agreement which expired in 1984 as a major sugar producer we are urging them to write a new agreement which would revive world prices yulo said if there is no agreement world prices will always be depressed particularly because the european community is <unk> its producers and dumping sugar on the markets he said current world prices holding steady at about 7 60 cents per pound were <unk> for the philippines where production costs ranged from 12 to 14 cents a pound if the price holds steady for a while at 7 60 cents i expect the level to rise to about 11 cents a pound by the end of this year he said yulo said economists forecast a bullish sugar market by 1990 with world consumption <unk> production he said sugar markets were holding up despite <unk> from artificial sweeteners and high fructose corn syrup but we are not happy with the reagan administration he said since <unk> we have been regular suppliers of sugar to the u s in 1982 when they restored the quota system they cut <unk> in half without any justification manila was <unk> watching washington's moves to cut domestic support prices to 12 cents a pound from 18 cents the u s agriculture department last december slashed its 12 month 1987 sugar import quota from the philippines to 143 780 short tons from 231 660 short tons in 1986 yulo said despite next year's increased production target some philippine mills were expected to shut down at least four of the 41 mills were not working during the 1986 87 season he said we expect two or three more to follow suit during the next season reuter 3\",\n",
              " \"<sos> the agriculture department's widening of louisiana gulf differentials will affect county posted prices for number two yellow corn in ten states a usda official said all counties in iowa will be affected as will counties which use the gulf to price corn in illinois indiana tennessee kentucky missouri mississippi arkansas alabama and louisiana said <unk> <unk> deputy director of commodity operations division for the usda usda last night notified the grain industry that effective immediately all gulf differentials used to price interior corn would be widened on a sliding scale basis of four to eight cts depending on what the differential is usda's action was taken to lower excessively high posted county prices for corn caused by high gulf prices we've been following this louisiana gulf situation for a month and we don't think it's going to get back in line in any nearby time <unk> said <unk> said usda will probably narrow back the gulf differentials when and if gulf prices <unk> if we're off the mark now because we're too high wouldn't we be as much off the mark if we're too low he said while forecasting more adjustments if gulf prices fall <unk> said no other changes in usda's price system are being planned right now we don't tinker we don't make changes <unk> and we don't make changes often he said reuter 3\",\n",
              " '<sos> <unk> <unk> oil and gas partnership said it completed the sale of interests in two major oil and gas fields to lt energy assets international corp for 21 mln dlrs the company said it sold about one half of its 50 pct interest in the oak hill and north <unk> fields its two largest producing properties it said it used about 20 mln dlrs of the proceeds to <unk> principal on its senior secured notes semi annual principal payments on the remaining 40 mln dlrs of notes have been satisfied until december 1988 as a result it said the company said the note agreements were amended to reflect an easing of some financial covenants and an increase of interest to 13 5 pct from 13 0 pct until december 1990 it said the <unk> exercise price for 1 125 000 warrants was also reduced to 50 cts from 1 50 dlrs the company said energy assets agreed to share the costs of increasing production at the oak hill field reuter 3',\n",
              " '<sos> strong south <unk> winds were keeping many vessels trapped in the ice off the finnish and swedish coasts in one of the worst icy periods in the baltic for many years the finnish board of navigation said in finland and sweden up to 50 vessels were reported to be stuck in the ice and even the largest of the <unk> <unk> were having difficulties in breaking through to the <unk> ships <unk> officials said however icy conditions in the southern baltic at the soviet oil ports of <unk> and <unk> had eased they said weather officials in neighbouring sweden said the icy conditions in the baltic were the worst for 30 years with ships fighting a losing battle to keep moving in the coastal stretches of the gulf of <unk> which <unk> finland and sweden the ice is up to one <unk> thick with <unk> and <unk> packing it into almost <unk> walls three metres high swedish <unk> officials said weather forecasts say winds may ease during the weekend but a further drop in temperature could bring shipping to a standstill the officials said reuter 3']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvC7VXXzDkJe"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdKHLC8_EIai",
        "outputId": "8c8ccc23-e436-42ea-ade7-e36d911b63cc"
      },
      "source": [
        "dtmvector = CountVectorizer()\n",
        "x_train_dtm = dtmvector.fit_transform(x_train)\n",
        "print(x_train_dtm.shape)\n",
        "\n",
        "print(x_train_dtm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8982, 9670)\n",
            "  (0, 8272)\t1\n",
            "  (0, 9181)\t2\n",
            "  (0, 7834)\t3\n",
            "  (0, 1677)\t1\n",
            "  (0, 7633)\t1\n",
            "  (0, 6365)\t3\n",
            "  (0, 5223)\t1\n",
            "  (0, 3143)\t1\n",
            "  (0, 1233)\t1\n",
            "  (0, 8303)\t1\n",
            "  (0, 2565)\t1\n",
            "  (0, 5213)\t2\n",
            "  (0, 3945)\t1\n",
            "  (0, 3608)\t1\n",
            "  (0, 6682)\t3\n",
            "  (0, 8055)\t3\n",
            "  (0, 4945)\t3\n",
            "  (0, 249)\t1\n",
            "  (0, 172)\t1\n",
            "  (0, 8932)\t6\n",
            "  (0, 383)\t1\n",
            "  (0, 3475)\t6\n",
            "  (0, 9218)\t1\n",
            "  (0, 4325)\t3\n",
            "  (0, 828)\t1\n",
            "  :\t:\n",
            "  (8981, 4219)\t1\n",
            "  (8981, 1863)\t1\n",
            "  (8981, 1590)\t1\n",
            "  (8981, 1261)\t1\n",
            "  (8981, 9246)\t1\n",
            "  (8981, 5025)\t1\n",
            "  (8981, 1837)\t1\n",
            "  (8981, 2191)\t2\n",
            "  (8981, 5451)\t1\n",
            "  (8981, 7489)\t1\n",
            "  (8981, 1573)\t1\n",
            "  (8981, 4941)\t1\n",
            "  (8981, 6117)\t1\n",
            "  (8981, 5183)\t1\n",
            "  (8981, 7852)\t1\n",
            "  (8981, 8153)\t1\n",
            "  (8981, 4024)\t1\n",
            "  (8981, 3909)\t1\n",
            "  (8981, 1315)\t1\n",
            "  (8981, 2358)\t1\n",
            "  (8981, 6081)\t2\n",
            "  (8981, 5418)\t1\n",
            "  (8981, 9133)\t1\n",
            "  (8981, 9594)\t1\n",
            "  (8981, 7294)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ1nGi4mDz9m",
        "outputId": "6238c2d2-2c72-4e52-f3d9-6933e2ea7474"
      },
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "tfidv = tfidf_transformer.fit_transform(x_train_dtm)\n",
        "print(tfidv.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8982, 9670)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "5VJqLxriD9i9",
        "outputId": "9f31ae9a-1cca-4b7c-cb2d-e2c1be432c67"
      },
      "source": [
        "'''\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score #정확도 계산\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "mod = MultinomialNB()\n",
        "\n",
        "x_test_dtm = dtmvector.transform(x_test)\n",
        "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환\n",
        "\n",
        "print(classification_report(y_test, mod.predict(tfidfv_test)))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-9a3306fdb630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtfidfv_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_dtm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#DTM을 TF-IDF 행렬로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidfv_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \"\"\"\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This MultinomialNB instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU9aEFNqE0Cb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}